{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10632457,"sourceType":"datasetVersion","datasetId":6582787}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:32:23.890552Z","iopub.execute_input":"2025-02-09T13:32:23.890828Z","iopub.status.idle":"2025-02-09T13:32:24.791668Z","shell.execute_reply.started":"2025-02-09T13:32:23.890798Z","shell.execute_reply":"2025-02-09T13:32:24.790854Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/multimodal-sentiment/Multimodal_dataset_assignment3/labels.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:32:24.793410Z","iopub.execute_input":"2025-02-09T13:32:24.793751Z","iopub.status.idle":"2025-02-09T13:32:24.872179Z","shell.execute_reply.started":"2025-02-09T13:32:24.793729Z","shell.execute_reply":"2025-02-09T13:32:24.871526Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:32:24.873524Z","iopub.execute_input":"2025-02-09T13:32:24.873812Z","iopub.status.idle":"2025-02-09T13:32:24.897702Z","shell.execute_reply.started":"2025-02-09T13:32:24.873783Z","shell.execute_reply":"2025-02-09T13:32:24.897065Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0    image_name  \\\n0           0   image_1.jpg   \n1           1  image_2.jpeg   \n2           2   image_3.JPG   \n3           3   image_4.png   \n4           4   image_5.png   \n\n                                            text_ocr  \\\n0  LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...   \n1  The best of #10 YearChallenge! Completed in le...   \n2  Sam Thorne @Strippin ( Follow Follow Saw every...   \n3              10 Year Challenge - Sweet Dee Edition   \n4  10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...   \n\n                                      text_corrected      humour  \\\n0  LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...   hilarious   \n1  The best of #10 YearChallenge! Completed in le...   not_funny   \n2  Sam Thorne @Strippin ( Follow Follow Saw every...  very_funny   \n3              10 Year Challenge - Sweet Dee Edition  very_funny   \n4  10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...   hilarious   \n\n           sarcasm       offensive      motivational overall_sentiment  \n0          general   not_offensive  not_motivational     very_positive  \n1          general   not_offensive      motivational     very_positive  \n2    not_sarcastic   not_offensive  not_motivational          positive  \n3  twisted_meaning  very_offensive      motivational          positive  \n4     very_twisted  very_offensive  not_motivational           neutral  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>image_name</th>\n      <th>text_ocr</th>\n      <th>text_corrected</th>\n      <th>humour</th>\n      <th>sarcasm</th>\n      <th>offensive</th>\n      <th>motivational</th>\n      <th>overall_sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>image_1.jpg</td>\n      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n      <td>hilarious</td>\n      <td>general</td>\n      <td>not_offensive</td>\n      <td>not_motivational</td>\n      <td>very_positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>image_2.jpeg</td>\n      <td>The best of #10 YearChallenge! Completed in le...</td>\n      <td>The best of #10 YearChallenge! Completed in le...</td>\n      <td>not_funny</td>\n      <td>general</td>\n      <td>not_offensive</td>\n      <td>motivational</td>\n      <td>very_positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>image_3.JPG</td>\n      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n      <td>very_funny</td>\n      <td>not_sarcastic</td>\n      <td>not_offensive</td>\n      <td>not_motivational</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>image_4.png</td>\n      <td>10 Year Challenge - Sweet Dee Edition</td>\n      <td>10 Year Challenge - Sweet Dee Edition</td>\n      <td>very_funny</td>\n      <td>twisted_meaning</td>\n      <td>very_offensive</td>\n      <td>motivational</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>image_5.png</td>\n      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n      <td>hilarious</td>\n      <td>very_twisted</td>\n      <td>very_offensive</td>\n      <td>not_motivational</td>\n      <td>neutral</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"df.isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:32:24.898355Z","iopub.execute_input":"2025-02-09T13:32:24.898652Z","iopub.status.idle":"2025-02-09T13:32:24.908222Z","shell.execute_reply.started":"2025-02-09T13:32:24.898631Z","shell.execute_reply":"2025-02-09T13:32:24.907551Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"Unnamed: 0             0\nimage_name             0\ntext_ocr             161\ntext_corrected         5\nhumour                 0\nsarcasm                0\noffensive              0\nmotivational           0\noverall_sentiment      0\ndtype: int64"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:32:24.909113Z","iopub.execute_input":"2025-02-09T13:32:24.909374Z","iopub.status.idle":"2025-02-09T13:32:24.921161Z","shell.execute_reply.started":"2025-02-09T13:32:24.909354Z","shell.execute_reply":"2025-02-09T13:32:24.920493Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Index(['Unnamed: 0', 'image_name', 'text_ocr', 'text_corrected', 'humour',\n       'sarcasm', 'offensive', 'motivational', 'overall_sentiment'],\n      dtype='object')"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"df = df.drop(columns=['Unnamed: 0','text_ocr'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:32:24.921885Z","iopub.execute_input":"2025-02-09T13:32:24.922179Z","iopub.status.idle":"2025-02-09T13:32:24.939071Z","shell.execute_reply.started":"2025-02-09T13:32:24.922151Z","shell.execute_reply":"2025-02-09T13:32:24.938394Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"df = df.dropna()\ndf.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:32:24.939909Z","iopub.execute_input":"2025-02-09T13:32:24.940218Z","iopub.status.idle":"2025-02-09T13:32:24.982083Z","shell.execute_reply.started":"2025-02-09T13:32:24.940184Z","shell.execute_reply":"2025-02-09T13:32:24.980681Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"     image_name                                     text_corrected  \\\n0   image_1.jpg  LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...   \n1  image_2.jpeg  The best of #10 YearChallenge! Completed in le...   \n2   image_3.JPG  Sam Thorne @Strippin ( Follow Follow Saw every...   \n3   image_4.png              10 Year Challenge - Sweet Dee Edition   \n4   image_5.png  10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...   \n\n       humour          sarcasm       offensive      motivational  \\\n0   hilarious          general   not_offensive  not_motivational   \n1   not_funny          general   not_offensive      motivational   \n2  very_funny    not_sarcastic   not_offensive  not_motivational   \n3  very_funny  twisted_meaning  very_offensive      motivational   \n4   hilarious     very_twisted  very_offensive  not_motivational   \n\n  overall_sentiment  \n0     very_positive  \n1     very_positive  \n2          positive  \n3          positive  \n4           neutral  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>text_corrected</th>\n      <th>humour</th>\n      <th>sarcasm</th>\n      <th>offensive</th>\n      <th>motivational</th>\n      <th>overall_sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>image_1.jpg</td>\n      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n      <td>hilarious</td>\n      <td>general</td>\n      <td>not_offensive</td>\n      <td>not_motivational</td>\n      <td>very_positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>image_2.jpeg</td>\n      <td>The best of #10 YearChallenge! Completed in le...</td>\n      <td>not_funny</td>\n      <td>general</td>\n      <td>not_offensive</td>\n      <td>motivational</td>\n      <td>very_positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>image_3.JPG</td>\n      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n      <td>very_funny</td>\n      <td>not_sarcastic</td>\n      <td>not_offensive</td>\n      <td>not_motivational</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>image_4.png</td>\n      <td>10 Year Challenge - Sweet Dee Edition</td>\n      <td>very_funny</td>\n      <td>twisted_meaning</td>\n      <td>very_offensive</td>\n      <td>motivational</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>image_5.png</td>\n      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n      <td>hilarious</td>\n      <td>very_twisted</td>\n      <td>very_offensive</td>\n      <td>not_motivational</td>\n      <td>neutral</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"import re\n\ndef clean_text(text):\n    # Remove @usernames\n    text = re.sub(r'@\\w+', '', text)\n    \n    # Remove emails\n    text = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', '', text)\n    \n    # Convert to lowercase\n    text = text.lower()\n    \n    # Remove all symbols except spaces and alphanumeric characters\n    text = re.sub(r'[^a-z0-9\\s]', '', text)\n    \n    # Remove extra spaces\n    text = re.sub(r'\\s+', ' ', text).strip()\n    \n    return text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:32:24.988403Z","iopub.execute_input":"2025-02-09T13:32:24.988667Z","iopub.status.idle":"2025-02-09T13:32:24.996396Z","shell.execute_reply.started":"2025-02-09T13:32:24.988644Z","shell.execute_reply":"2025-02-09T13:32:24.995700Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"df2 = df.copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:32:24.998933Z","iopub.execute_input":"2025-02-09T13:32:24.999441Z","iopub.status.idle":"2025-02-09T13:32:25.012243Z","shell.execute_reply.started":"2025-02-09T13:32:24.999412Z","shell.execute_reply":"2025-02-09T13:32:25.011273Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"df2['text_corrected'] = df2['text_corrected'].apply(clean_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:32:25.012742Z","iopub.execute_input":"2025-02-09T13:32:25.012959Z","iopub.status.idle":"2025-02-09T13:32:25.166360Z","shell.execute_reply.started":"2025-02-09T13:32:25.012937Z","shell.execute_reply":"2025-02-09T13:32:25.165578Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"df2.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:32:25.167169Z","iopub.execute_input":"2025-02-09T13:32:25.167437Z","iopub.status.idle":"2025-02-09T13:32:25.179173Z","shell.execute_reply.started":"2025-02-09T13:32:25.167417Z","shell.execute_reply":"2025-02-09T13:32:25.178298Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"     image_name                                     text_corrected  \\\n0   image_1.jpg  look there my friend lightyear now all sohalik...   \n1  image_2.jpeg  the best of 10 yearchallenge completed in less...   \n2   image_3.JPG  sam thorne follow follow saw everyone posting ...   \n3   image_4.png                10 year challenge sweet dee edition   \n4   image_5.png  10 year challenge with no filter 47 hilarious ...   \n\n       humour          sarcasm       offensive      motivational  \\\n0   hilarious          general   not_offensive  not_motivational   \n1   not_funny          general   not_offensive      motivational   \n2  very_funny    not_sarcastic   not_offensive  not_motivational   \n3  very_funny  twisted_meaning  very_offensive      motivational   \n4   hilarious     very_twisted  very_offensive  not_motivational   \n\n  overall_sentiment  \n0     very_positive  \n1     very_positive  \n2          positive  \n3          positive  \n4           neutral  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>text_corrected</th>\n      <th>humour</th>\n      <th>sarcasm</th>\n      <th>offensive</th>\n      <th>motivational</th>\n      <th>overall_sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>image_1.jpg</td>\n      <td>look there my friend lightyear now all sohalik...</td>\n      <td>hilarious</td>\n      <td>general</td>\n      <td>not_offensive</td>\n      <td>not_motivational</td>\n      <td>very_positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>image_2.jpeg</td>\n      <td>the best of 10 yearchallenge completed in less...</td>\n      <td>not_funny</td>\n      <td>general</td>\n      <td>not_offensive</td>\n      <td>motivational</td>\n      <td>very_positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>image_3.JPG</td>\n      <td>sam thorne follow follow saw everyone posting ...</td>\n      <td>very_funny</td>\n      <td>not_sarcastic</td>\n      <td>not_offensive</td>\n      <td>not_motivational</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>image_4.png</td>\n      <td>10 year challenge sweet dee edition</td>\n      <td>very_funny</td>\n      <td>twisted_meaning</td>\n      <td>very_offensive</td>\n      <td>motivational</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>image_5.png</td>\n      <td>10 year challenge with no filter 47 hilarious ...</td>\n      <td>hilarious</td>\n      <td>very_twisted</td>\n      <td>very_offensive</td>\n      <td>not_motivational</td>\n      <td>neutral</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords\nnltk.download('stopwords')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:32:25.180064Z","iopub.execute_input":"2025-02-09T13:32:25.180328Z","iopub.status.idle":"2025-02-09T13:32:26.485461Z","shell.execute_reply.started":"2025-02-09T13:32:25.180297Z","shell.execute_reply":"2025-02-09T13:32:26.484667Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"def remove_stopwords(text, custom_stopwords=None):\n    # Load default stopwords\n    stop_words = set(stopwords.words('english'))\n    stop_words.update({'follow'})\n\n    # Remove stopwords\n    filtered_text = ' '.join(word for word in text.split() if word not in stop_words)\n    \n    return filtered_text\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:32:26.486246Z","iopub.execute_input":"2025-02-09T13:32:26.486613Z","iopub.status.idle":"2025-02-09T13:32:26.491081Z","shell.execute_reply.started":"2025-02-09T13:32:26.486591Z","shell.execute_reply":"2025-02-09T13:32:26.490073Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"df2['text_corrected'] = df2['text_corrected'].apply(remove_stopwords)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:32:26.491941Z","iopub.execute_input":"2025-02-09T13:32:26.492264Z","iopub.status.idle":"2025-02-09T13:32:27.253907Z","shell.execute_reply.started":"2025-02-09T13:32:26.492233Z","shell.execute_reply":"2025-02-09T13:32:27.253034Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"df2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:32:27.254669Z","iopub.execute_input":"2025-02-09T13:32:27.254958Z","iopub.status.idle":"2025-02-09T13:32:27.266477Z","shell.execute_reply.started":"2025-02-09T13:32:27.254928Z","shell.execute_reply":"2025-02-09T13:32:27.265566Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"          image_name                                     text_corrected  \\\n0        image_1.jpg  look friend lightyear sohalikut trend play 10 ...   \n1       image_2.jpeg  best 10 yearchallenge completed less 4 years k...   \n2        image_3.JPG  sam thorne saw everyone posting 2009 vs 2019 p...   \n3        image_4.png                10 year challenge sweet dee edition   \n4        image_5.png  10 year challenge filter 47 hilarious 10 year ...   \n...              ...                                                ...   \n6987  image_6988.jpg  tuesday mardi gras wednesday valentines friday...   \n6988  image_6989.jpg  must watch movies 2017 iti chennai memes maana...   \n6989  image_6990.png  less talking planning soda junk food complaini...   \n6990  image_6991.jpg  time fantasy one time unless make time arhtist...   \n6991  image_6992.jpg  starting point every good idea arhtistic licen...   \n\n          humour          sarcasm       offensive      motivational  \\\n0      hilarious          general   not_offensive  not_motivational   \n1      not_funny          general   not_offensive      motivational   \n2     very_funny    not_sarcastic   not_offensive  not_motivational   \n3     very_funny  twisted_meaning  very_offensive      motivational   \n4      hilarious     very_twisted  very_offensive  not_motivational   \n...          ...              ...             ...               ...   \n6987  very_funny  twisted_meaning  very_offensive      motivational   \n6988       funny  twisted_meaning   not_offensive  not_motivational   \n6989       funny          general          slight  not_motivational   \n6990   not_funny  twisted_meaning   not_offensive      motivational   \n6991   not_funny    not_sarcastic   not_offensive      motivational   \n\n     overall_sentiment  \n0        very_positive  \n1        very_positive  \n2             positive  \n3             positive  \n4              neutral  \n...                ...  \n6987           neutral  \n6988           neutral  \n6989          positive  \n6990     very_positive  \n6991          positive  \n\n[6987 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>text_corrected</th>\n      <th>humour</th>\n      <th>sarcasm</th>\n      <th>offensive</th>\n      <th>motivational</th>\n      <th>overall_sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>image_1.jpg</td>\n      <td>look friend lightyear sohalikut trend play 10 ...</td>\n      <td>hilarious</td>\n      <td>general</td>\n      <td>not_offensive</td>\n      <td>not_motivational</td>\n      <td>very_positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>image_2.jpeg</td>\n      <td>best 10 yearchallenge completed less 4 years k...</td>\n      <td>not_funny</td>\n      <td>general</td>\n      <td>not_offensive</td>\n      <td>motivational</td>\n      <td>very_positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>image_3.JPG</td>\n      <td>sam thorne saw everyone posting 2009 vs 2019 p...</td>\n      <td>very_funny</td>\n      <td>not_sarcastic</td>\n      <td>not_offensive</td>\n      <td>not_motivational</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>image_4.png</td>\n      <td>10 year challenge sweet dee edition</td>\n      <td>very_funny</td>\n      <td>twisted_meaning</td>\n      <td>very_offensive</td>\n      <td>motivational</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>image_5.png</td>\n      <td>10 year challenge filter 47 hilarious 10 year ...</td>\n      <td>hilarious</td>\n      <td>very_twisted</td>\n      <td>very_offensive</td>\n      <td>not_motivational</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6987</th>\n      <td>image_6988.jpg</td>\n      <td>tuesday mardi gras wednesday valentines friday...</td>\n      <td>very_funny</td>\n      <td>twisted_meaning</td>\n      <td>very_offensive</td>\n      <td>motivational</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>6988</th>\n      <td>image_6989.jpg</td>\n      <td>must watch movies 2017 iti chennai memes maana...</td>\n      <td>funny</td>\n      <td>twisted_meaning</td>\n      <td>not_offensive</td>\n      <td>not_motivational</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>6989</th>\n      <td>image_6990.png</td>\n      <td>less talking planning soda junk food complaini...</td>\n      <td>funny</td>\n      <td>general</td>\n      <td>slight</td>\n      <td>not_motivational</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>6990</th>\n      <td>image_6991.jpg</td>\n      <td>time fantasy one time unless make time arhtist...</td>\n      <td>not_funny</td>\n      <td>twisted_meaning</td>\n      <td>not_offensive</td>\n      <td>motivational</td>\n      <td>very_positive</td>\n    </tr>\n    <tr>\n      <th>6991</th>\n      <td>image_6992.jpg</td>\n      <td>starting point every good idea arhtistic licen...</td>\n      <td>not_funny</td>\n      <td>not_sarcastic</td>\n      <td>not_offensive</td>\n      <td>motivational</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n<p>6987 rows × 7 columns</p>\n</div>"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"df2['overall_sentiment'] = df2['overall_sentiment'].replace({'very_positive': 2, 'positive': 2, 'negative': 0, 'very_negative': 0, 'neutral': 1})\ndf2['overall_sentiment'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:32:27.267344Z","iopub.execute_input":"2025-02-09T13:32:27.267649Z","iopub.status.idle":"2025-02-09T13:32:27.297287Z","shell.execute_reply.started":"2025-02-09T13:32:27.267619Z","shell.execute_reply":"2025-02-09T13:32:27.296399Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-16-86f3814db7b8>:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  df2['overall_sentiment'] = df2['overall_sentiment'].replace({'very_positive': 2, 'positive': 2, 'negative': 0, 'very_negative': 0, 'neutral': 1})\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"overall_sentiment\n2    4156\n1    2200\n0     631\nName: count, dtype: int64"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"df2['humour_sentiment'] = df2['humour'].replace({'very_funny': 1, 'funny': 1, 'hilarious': 1, 'not_funny': 0})\n\ndf2['sarcasm_sentiment'] = df2['sarcasm'].replace({'very_twisted': 1, 'twisted_meaning': 1, 'general': 1, 'not_sarcastic': 0})\n\ndf2['offensive_sentiment'] = df2['offensive'].replace({'very_offensive': 1, 'hateful_offensive': 1, 'slight': 1, 'not_offensive': 0})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:32:27.298205Z","iopub.execute_input":"2025-02-09T13:32:27.298468Z","iopub.status.idle":"2025-02-09T13:32:27.316314Z","shell.execute_reply.started":"2025-02-09T13:32:27.298442Z","shell.execute_reply":"2025-02-09T13:32:27.315503Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-17-ef3b932b4a36>:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  df2['humour_sentiment'] = df2['humour'].replace({'very_funny': 1, 'funny': 1, 'hilarious': 1, 'not_funny': 0})\n<ipython-input-17-ef3b932b4a36>:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  df2['sarcasm_sentiment'] = df2['sarcasm'].replace({'very_twisted': 1, 'twisted_meaning': 1, 'general': 1, 'not_sarcastic': 0})\n<ipython-input-17-ef3b932b4a36>:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  df2['offensive_sentiment'] = df2['offensive'].replace({'very_offensive': 1, 'hateful_offensive': 1, 'slight': 1, 'not_offensive': 0})\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"df2.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:32:27.317131Z","iopub.execute_input":"2025-02-09T13:32:27.317411Z","iopub.status.idle":"2025-02-09T13:32:27.330138Z","shell.execute_reply.started":"2025-02-09T13:32:27.317385Z","shell.execute_reply":"2025-02-09T13:32:27.329354Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"     image_name                                     text_corrected  \\\n0   image_1.jpg  look friend lightyear sohalikut trend play 10 ...   \n1  image_2.jpeg  best 10 yearchallenge completed less 4 years k...   \n2   image_3.JPG  sam thorne saw everyone posting 2009 vs 2019 p...   \n3   image_4.png                10 year challenge sweet dee edition   \n4   image_5.png  10 year challenge filter 47 hilarious 10 year ...   \n\n       humour          sarcasm       offensive      motivational  \\\n0   hilarious          general   not_offensive  not_motivational   \n1   not_funny          general   not_offensive      motivational   \n2  very_funny    not_sarcastic   not_offensive  not_motivational   \n3  very_funny  twisted_meaning  very_offensive      motivational   \n4   hilarious     very_twisted  very_offensive  not_motivational   \n\n   overall_sentiment  humour_sentiment  sarcasm_sentiment  offensive_sentiment  \n0                  2                 1                  1                    0  \n1                  2                 0                  1                    0  \n2                  2                 1                  0                    0  \n3                  2                 1                  1                    1  \n4                  1                 1                  1                    1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>text_corrected</th>\n      <th>humour</th>\n      <th>sarcasm</th>\n      <th>offensive</th>\n      <th>motivational</th>\n      <th>overall_sentiment</th>\n      <th>humour_sentiment</th>\n      <th>sarcasm_sentiment</th>\n      <th>offensive_sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>image_1.jpg</td>\n      <td>look friend lightyear sohalikut trend play 10 ...</td>\n      <td>hilarious</td>\n      <td>general</td>\n      <td>not_offensive</td>\n      <td>not_motivational</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>image_2.jpeg</td>\n      <td>best 10 yearchallenge completed less 4 years k...</td>\n      <td>not_funny</td>\n      <td>general</td>\n      <td>not_offensive</td>\n      <td>motivational</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>image_3.JPG</td>\n      <td>sam thorne saw everyone posting 2009 vs 2019 p...</td>\n      <td>very_funny</td>\n      <td>not_sarcastic</td>\n      <td>not_offensive</td>\n      <td>not_motivational</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>image_4.png</td>\n      <td>10 year challenge sweet dee edition</td>\n      <td>very_funny</td>\n      <td>twisted_meaning</td>\n      <td>very_offensive</td>\n      <td>motivational</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>image_5.png</td>\n      <td>10 year challenge filter 47 hilarious 10 year ...</td>\n      <td>hilarious</td>\n      <td>very_twisted</td>\n      <td>very_offensive</td>\n      <td>not_motivational</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import DistilBertTokenizer, DistilBertModel\nfrom transformers import ViTImageProcessor, ViTModel\nfrom PIL import Image, ImageFile\nimport pandas as pd\nfrom sklearn.metrics import f1_score\nfrom sklearn.decomposition import PCA\nimport torch.optim as optim\nimport numpy as np\nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:32:27.330904Z","iopub.execute_input":"2025-02-09T13:32:27.331195Z","iopub.status.idle":"2025-02-09T13:32:46.559862Z","shell.execute_reply.started":"2025-02-09T13:32:27.331168Z","shell.execute_reply":"2025-02-09T13:32:46.559071Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# Configuration\nTEXT_MODEL_NAME = 'distilbert-base-uncased'\nIMAGE_MODEL_NAME = 'google/vit-base-patch16-224'\nMAX_LENGTH = 128\nBATCH_SIZE = 32\nEPOCHS = 10\nLEARNING_RATE = 2e-5\nPCA_COMPONENTS = 256  # Reduce feature dimensions\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:32:46.560869Z","iopub.execute_input":"2025-02-09T13:32:46.561518Z","iopub.status.idle":"2025-02-09T13:32:46.652846Z","shell.execute_reply.started":"2025-02-09T13:32:46.561487Z","shell.execute_reply":"2025-02-09T13:32:46.651960Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# Initialize processors\ntext_tokenizer = DistilBertTokenizer.from_pretrained(TEXT_MODEL_NAME)\nimage_processor = ViTImageProcessor.from_pretrained(IMAGE_MODEL_NAME)\ntext_model = DistilBertModel.from_pretrained(TEXT_MODEL_NAME).to(DEVICE)\nimage_model = ViTModel.from_pretrained(IMAGE_MODEL_NAME).to(DEVICE)\n\n# Freeze transformers to avoid recomputation\ntext_model.eval()\nimage_model.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:32:46.653924Z","iopub.execute_input":"2025-02-09T13:32:46.654393Z","iopub.status.idle":"2025-02-09T13:32:52.214729Z","shell.execute_reply.started":"2025-02-09T13:32:46.654358Z","shell.execute_reply":"2025-02-09T13:32:52.213863Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"378b69ca9dc9437984bd1000773cd36f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e8eb9546cfc4bc9902b21091fb0fd53"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2036508407f412cb27b51ad8bcec8f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6fba2681863a4952a1eb448d518f0f04"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2698e77cc7e74544b7d131b9d755cd92"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f438c4fd20204406be677ee5cbc0e25f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/69.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"268b80a0e13f4bf99572551882cefe43"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4396a2187f5e46929adaa770d4b5bbff"}},"metadata":{}},{"name":"stderr","text":"Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"ViTModel(\n  (embeddings): ViTEmbeddings(\n    (patch_embeddings): ViTPatchEmbeddings(\n      (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n    )\n    (dropout): Dropout(p=0.0, inplace=False)\n  )\n  (encoder): ViTEncoder(\n    (layer): ModuleList(\n      (0-11): 12 x ViTLayer(\n        (attention): ViTSdpaAttention(\n          (attention): ViTSdpaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (output): ViTSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (intermediate): ViTIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): ViTOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      )\n    )\n  )\n  (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n  (pooler): ViTPooler(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (activation): Tanh()\n  )\n)"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"def preprocess_data(dataframe):\n    texts = dataframe['text_corrected'].tolist()\n    image_dir = \"/kaggle/input/multimodal-sentiment/Multimodal_dataset_assignment3/images\"\n    image_paths = dataframe['image_name'].apply(lambda name: os.path.join(image_dir, name))\n    # image_paths = dataframe['image_path'].tolist()\n    labels = torch.tensor(dataframe[['humour_sentiment', 'sarcasm_sentiment', 'offensive_sentiment']].values, dtype=torch.float)\n    \n    text_features, image_features = [], []\n    \n    with torch.no_grad():\n        for text, image_path in zip(texts, image_paths):\n            text_inputs = text_tokenizer(text, max_length=MAX_LENGTH, padding='max_length', truncation=True, return_tensors='pt').to(DEVICE)\n            text_output = text_model(**text_inputs).last_hidden_state[:, 0, :].cpu().numpy()\n\n            ImageFile.LOAD_TRUNCATED_IMAGES = True\n            image = Image.open(image_path).convert('RGB')\n            image_inputs = image_processor(images=image, return_tensors='pt').to(DEVICE)\n            image_output = image_model(**image_inputs).last_hidden_state[:, 0, :].cpu().numpy()\n            \n            text_features.append(text_output.squeeze())\n            image_features.append(image_output.squeeze())\n    \n    return np.array(text_features), np.array(image_features), labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:32:52.215614Z","iopub.execute_input":"2025-02-09T13:32:52.215856Z","iopub.status.idle":"2025-02-09T13:32:52.221787Z","shell.execute_reply.started":"2025-02-09T13:32:52.215825Z","shell.execute_reply":"2025-02-09T13:32:52.221040Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"class MemeDataset(Dataset):\n    def __init__(self, text_features, image_features, labels):\n        self.text_features = text_features\n        self.image_features = image_features\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.text_features)\n\n    def __getitem__(self, idx):\n        return {\n            'text_features': torch.tensor(self.text_features[idx], dtype=torch.float),\n            'image_features': torch.tensor(self.image_features[idx], dtype=torch.float),\n            'labels': self.labels[idx]\n        }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:32:52.222673Z","iopub.execute_input":"2025-02-09T13:32:52.222873Z","iopub.status.idle":"2025-02-09T13:32:52.244728Z","shell.execute_reply.started":"2025-02-09T13:32:52.222855Z","shell.execute_reply":"2025-02-09T13:32:52.243969Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"class MultimodalModel(nn.Module):\n    def __init__(self, input_dim):\n        super().__init__()\n        self.fc_humor = nn.Linear(input_dim, 1)\n        self.fc_sarcasm = nn.Linear(input_dim, 1)\n        self.fc_offensive = nn.Linear(input_dim, 1)\n        self.dropout = nn.Dropout(0.1)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, text_features, image_features):\n        combined = torch.cat([text_features, image_features], dim=1)\n        combined = self.dropout(combined)\n        \n        humor = self.sigmoid(self.fc_humor(combined))\n        sarcasm = self.sigmoid(self.fc_sarcasm(combined))\n        offensive = self.sigmoid(self.fc_offensive(combined))\n        \n        return torch.cat([humor, sarcasm, offensive], dim=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:32:52.245418Z","iopub.execute_input":"2025-02-09T13:32:52.245645Z","iopub.status.idle":"2025-02-09T13:32:52.262037Z","shell.execute_reply.started":"2025-02-09T13:32:52.245625Z","shell.execute_reply":"2025-02-09T13:32:52.261052Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"def evaluate(model, loader, device):\n    model.eval()\n    humor_preds, humor_labels = [], []\n    sarcasm_preds, sarcasm_labels = [], []\n    offensive_preds, offensive_labels = [], []\n    \n    with torch.no_grad():\n        for batch in loader:\n            text_features = batch['text_features'].to(device)\n            image_features = batch['image_features'].to(device)\n            labels = batch['labels'].cpu().numpy()\n            \n            outputs = model(text_features, image_features).cpu().numpy()\n            preds = (outputs >= 0.5).astype(int)\n            \n            humor_preds.extend(preds[:, 0])\n            sarcasm_preds.extend(preds[:, 1])\n            offensive_preds.extend(preds[:, 2])\n            \n            humor_labels.extend(labels[:, 0])\n            sarcasm_labels.extend(labels[:, 1])\n            offensive_labels.extend(labels[:, 2])\n    \n    metrics = {\n        'humor_f1': f1_score(humor_labels, humor_preds, average='macro'),\n        'sarcasm_f1': f1_score(sarcasm_labels, sarcasm_preds, average='macro'),\n        'offensive_f1': f1_score(offensive_labels, offensive_preds, average='macro')\n    }\n    metrics['avg_f1'] = sum(metrics.values()) / 3\n    return metrics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:32:52.263039Z","iopub.execute_input":"2025-02-09T13:32:52.263316Z","iopub.status.idle":"2025-02-09T13:32:52.278808Z","shell.execute_reply.started":"2025-02-09T13:32:52.263287Z","shell.execute_reply":"2025-02-09T13:32:52.277904Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n# Split dataset\ntrain_df, test_df = train_test_split(df2, test_size=0.2, random_state=42)\n\ntrain_text, train_image, train_labels = preprocess_data(train_df)\nval_text, test_image, test_labels = preprocess_data(test_df)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:32:52.282100Z","iopub.execute_input":"2025-02-09T13:32:52.282305Z","iopub.status.idle":"2025-02-09T13:36:44.614819Z","shell.execute_reply.started":"2025-02-09T13:32:52.282288Z","shell.execute_reply":"2025-02-09T13:36:44.613906Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"pca = PCA(n_components=PCA_COMPONENTS)\ntrain_text = pca.fit_transform(train_text)\ntrain_image = pca.fit_transform(train_image)\nval_image = pca.transform(test_image)\nval_text = pca.transform(val_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:36:44.616173Z","iopub.execute_input":"2025-02-09T13:36:44.616482Z","iopub.status.idle":"2025-02-09T13:36:45.311921Z","shell.execute_reply.started":"2025-02-09T13:36:44.616454Z","shell.execute_reply":"2025-02-09T13:36:45.311225Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"# Create datasets\ntrain_dataset = MemeDataset(train_text, train_image, train_labels)\nval_dataset = MemeDataset(val_text, val_image, test_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:36:45.312726Z","iopub.execute_input":"2025-02-09T13:36:45.313048Z","iopub.status.idle":"2025-02-09T13:36:45.316701Z","shell.execute_reply.started":"2025-02-09T13:36:45.313018Z","shell.execute_reply":"2025-02-09T13:36:45.315636Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:36:45.317571Z","iopub.execute_input":"2025-02-09T13:36:45.317787Z","iopub.status.idle":"2025-02-09T13:36:45.332347Z","shell.execute_reply.started":"2025-02-09T13:36:45.317768Z","shell.execute_reply":"2025-02-09T13:36:45.331679Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"model = MultimodalModel(input_dim=PCA_COMPONENTS * 2).to(DEVICE)\noptimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\ncriterion = nn.BCELoss()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:36:45.333042Z","iopub.execute_input":"2025-02-09T13:36:45.333237Z","iopub.status.idle":"2025-02-09T13:36:45.348011Z","shell.execute_reply.started":"2025-02-09T13:36:45.333218Z","shell.execute_reply":"2025-02-09T13:36:45.347376Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"# train(model, train_loader, val_loader, optimizer, criterion, DEVICE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:36:45.348669Z","iopub.execute_input":"2025-02-09T13:36:45.348873Z","iopub.status.idle":"2025-02-09T13:36:45.359048Z","shell.execute_reply.started":"2025-02-09T13:36:45.348855Z","shell.execute_reply":"2025-02-09T13:36:45.358260Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"model.train()\nfor epoch in range(EPOCHS):\n    total_loss = 0\n    for batch in train_loader:\n            optimizer.zero_grad()\n            \n            text_features = batch['text_features'].to(DEVICE)\n            image_features = batch['image_features'].to(DEVICE)\n            labels = batch['labels'].to(DEVICE)\n            \n            outputs = model(text_features, image_features)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n            total_loss += loss.item()\n        \n    val_metrics = evaluate(model, val_loader, DEVICE)\n    print(f\"Epoch {epoch+1}/{EPOCHS}\")\n    print(f\"Train Loss: {total_loss/len(train_loader):.4f}\")\n    print(f\"Val F1 Scores - Humor: {val_metrics['humor_f1']:.4f}, \"\n              f\"Sarcasm: {val_metrics['sarcasm_f1']:.4f}, \"\n              f\"Offensive: {val_metrics['offensive_f1']:.4f}\")\n    print(f\"Avg F1: {val_metrics['avg_f1']:.4f}\\n\")\nval_metrics = evaluate(model, val_loader, DEVICE)\ncheckpoint = {\n                'epoch': epoch,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'loss': loss,\n                'val_f1': val_metrics['avg_f1']\n                }\n\ntorch.save(checkpoint, 'checkpoint_TaskB.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:36:45.359782Z","iopub.execute_input":"2025-02-09T13:36:45.360074Z","iopub.status.idle":"2025-02-09T13:36:50.425770Z","shell.execute_reply.started":"2025-02-09T13:36:45.360047Z","shell.execute_reply":"2025-02-09T13:36:50.424747Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\nTrain Loss: 0.7307\nVal F1 Scores - Humor: 0.4212, Sarcasm: 0.4132, Offensive: 0.5120\nAvg F1: 0.4488\n\nEpoch 2/10\nTrain Loss: 0.7242\nVal F1 Scores - Humor: 0.4203, Sarcasm: 0.4149, Offensive: 0.5073\nAvg F1: 0.4475\n\nEpoch 3/10\nTrain Loss: 0.7221\nVal F1 Scores - Humor: 0.4177, Sarcasm: 0.4168, Offensive: 0.5073\nAvg F1: 0.4473\n\nEpoch 4/10\nTrain Loss: 0.7198\nVal F1 Scores - Humor: 0.4186, Sarcasm: 0.4185, Offensive: 0.5045\nAvg F1: 0.4472\n\nEpoch 5/10\nTrain Loss: 0.7176\nVal F1 Scores - Humor: 0.4160, Sarcasm: 0.4213, Offensive: 0.5028\nAvg F1: 0.4467\n\nEpoch 6/10\nTrain Loss: 0.7157\nVal F1 Scores - Humor: 0.4127, Sarcasm: 0.4228, Offensive: 0.4959\nAvg F1: 0.4438\n\nEpoch 7/10\nTrain Loss: 0.7135\nVal F1 Scores - Humor: 0.4144, Sarcasm: 0.4267, Offensive: 0.4957\nAvg F1: 0.4456\n\nEpoch 8/10\nTrain Loss: 0.7116\nVal F1 Scores - Humor: 0.4170, Sarcasm: 0.4302, Offensive: 0.4910\nAvg F1: 0.4461\n\nEpoch 9/10\nTrain Loss: 0.7096\nVal F1 Scores - Humor: 0.4178, Sarcasm: 0.4284, Offensive: 0.4888\nAvg F1: 0.4450\n\nEpoch 10/10\nTrain Loss: 0.7075\nVal F1 Scores - Humor: 0.4176, Sarcasm: 0.4306, Offensive: 0.4912\nAvg F1: 0.4465\n\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"checkpoint","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:36:50.426666Z","iopub.execute_input":"2025-02-09T13:36:50.427029Z","iopub.status.idle":"2025-02-09T13:36:50.731962Z","shell.execute_reply.started":"2025-02-09T13:36:50.426977Z","shell.execute_reply":"2025-02-09T13:36:50.731132Z"}},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"{'epoch': 9,\n 'model_state_dict': OrderedDict([('fc_humor.weight',\n               tensor([[-3.5462e-02,  3.1245e-02,  3.9048e-02,  2.0173e-02,  2.7318e-02,\n                         3.6473e-02, -1.7930e-02, -3.4449e-02, -4.3854e-03, -4.2623e-02,\n                         2.7726e-02,  3.1700e-02,  3.1543e-03, -1.7677e-02,  3.1338e-02,\n                        -2.9134e-03,  4.2106e-03,  1.1683e-02,  3.7953e-02,  4.2601e-02,\n                        -9.0276e-03, -1.4235e-02, -2.6410e-02,  2.4127e-02, -1.6019e-02,\n                        -9.5240e-03, -2.2248e-02, -2.1863e-02, -1.7697e-02, -4.4343e-02,\n                         3.6130e-02,  3.6768e-02,  1.9146e-02,  1.6534e-02, -7.2480e-03,\n                        -4.1845e-03, -9.0295e-04, -1.7843e-03,  1.9514e-02,  1.4926e-02,\n                        -2.7894e-04, -4.3365e-02, -1.9688e-02, -2.6157e-03,  1.3865e-02,\n                         5.5926e-03, -3.0406e-02, -3.9505e-02,  2.3815e-02,  1.3440e-02,\n                        -3.0015e-02,  3.6042e-02, -3.4239e-02, -2.9194e-02, -1.3840e-02,\n                         8.2965e-03,  1.6580e-02,  2.0223e-02, -3.8381e-02, -2.6054e-02,\n                         4.2624e-02,  4.5230e-03, -3.3335e-02,  4.5053e-03,  1.5976e-02,\n                        -3.5285e-02, -2.6520e-03, -2.6888e-02,  1.8353e-02,  2.5560e-02,\n                         1.6605e-02, -3.8309e-03,  9.8904e-03,  3.0354e-02, -3.7349e-02,\n                        -1.2961e-02, -1.0982e-02, -3.2259e-02, -2.4296e-02,  1.1661e-02,\n                         6.7046e-03, -3.8008e-02,  1.6926e-02,  2.9165e-02, -3.0597e-02,\n                         6.9791e-03, -5.4165e-03, -4.0865e-02, -2.1847e-02, -2.7278e-03,\n                        -5.9127e-03,  2.8153e-02,  1.4553e-02, -1.0403e-02, -8.2930e-03,\n                         3.1371e-02, -1.4938e-02, -2.2786e-02, -3.5964e-03,  3.7643e-02,\n                         6.3675e-03,  1.2622e-02, -3.6945e-02, -7.5340e-03,  1.4303e-02,\n                         9.9077e-03,  5.2644e-03, -2.3636e-02,  3.2616e-02,  3.4452e-02,\n                         3.9823e-02, -3.4090e-02, -6.3483e-03,  3.1347e-02, -3.8730e-02,\n                        -1.5543e-02, -2.3502e-03,  1.4403e-03,  1.2508e-02, -7.9361e-03,\n                         1.5611e-02, -3.2994e-02, -4.8094e-03, -3.3864e-02, -1.2851e-02,\n                         1.0634e-02,  3.3787e-02,  3.9393e-02, -8.5039e-03,  2.1640e-02,\n                        -2.9922e-02, -2.6869e-02, -1.4743e-03, -3.1601e-02,  1.3912e-02,\n                         2.7678e-02, -2.5342e-03,  2.4670e-02, -1.1219e-02, -3.1123e-02,\n                         3.9795e-03, -6.2614e-03, -4.0057e-02, -3.2968e-02,  2.5560e-02,\n                        -3.0769e-02, -2.0624e-02,  3.3517e-02, -8.4200e-03, -3.8916e-02,\n                         1.9804e-02, -1.1345e-02,  1.5054e-02, -2.3144e-03, -3.0013e-02,\n                        -3.8056e-02,  1.2689e-02,  2.7271e-02, -4.1112e-02, -2.8821e-02,\n                         1.9757e-02, -3.8112e-03, -2.6815e-02,  1.3716e-03, -2.1787e-02,\n                         3.0997e-02,  3.1330e-02, -2.5199e-02, -1.4926e-02,  2.8992e-02,\n                         7.9119e-03,  1.1520e-02, -1.6861e-02, -1.5939e-03, -3.5522e-02,\n                         2.4822e-02, -7.7626e-03,  3.2126e-02, -2.6094e-02, -4.3724e-02,\n                         1.2120e-02,  9.2685e-03,  1.8314e-02,  3.0463e-02,  3.2301e-02,\n                         4.1496e-02, -2.9848e-02,  1.9175e-02, -7.1722e-04,  1.1994e-02,\n                        -4.2771e-03, -3.2326e-02, -1.7420e-02, -3.4226e-02, -2.3474e-02,\n                        -1.5771e-02, -2.5682e-02, -3.1499e-02,  2.7737e-02,  2.7825e-02,\n                        -2.6481e-02, -9.3921e-03, -2.4504e-02,  4.0379e-02,  1.1647e-02,\n                         3.9164e-02, -6.4925e-03, -1.0013e-02, -1.8597e-03, -1.6900e-02,\n                         2.8283e-02,  2.2890e-03, -2.1058e-02,  1.8357e-03, -2.6116e-02,\n                         9.4089e-03, -2.7605e-02, -3.3427e-02, -3.5585e-02,  3.2861e-02,\n                        -2.6065e-02, -3.3691e-02,  3.2872e-02,  4.5668e-03, -4.1085e-03,\n                         3.5373e-02, -2.3599e-02, -1.9514e-02,  4.3526e-02,  6.6107e-03,\n                         3.1480e-02,  2.5619e-02,  4.3580e-02,  3.9222e-02, -3.3623e-02,\n                         4.3294e-02,  2.4481e-02,  3.5233e-02,  2.8392e-02, -4.1958e-02,\n                        -1.8824e-02,  4.1323e-03,  2.1129e-03, -5.9948e-03, -3.2488e-03,\n                        -1.6403e-02,  7.6711e-03, -2.3924e-02, -5.3391e-03,  2.0337e-02,\n                        -5.7946e-03,  2.5242e-02, -1.1055e-02,  7.5273e-03,  2.1227e-02,\n                        -3.4801e-02,  3.0750e-02, -1.6251e-02, -1.9959e-02,  1.6317e-03,\n                         2.3581e-02,  1.0151e-02, -3.0916e-02, -1.4847e-02,  6.0809e-03,\n                         2.0771e-02, -1.9486e-02, -2.5984e-02,  2.6791e-02, -6.4252e-03,\n                        -1.4785e-02,  4.1969e-03,  1.4793e-02, -1.4343e-02, -2.6624e-02,\n                         2.8825e-02,  3.5505e-02,  2.2352e-02, -1.4549e-02,  2.5467e-02,\n                         3.5632e-02,  2.6506e-02, -3.4494e-02,  1.9637e-02, -2.1387e-02,\n                         2.4467e-02,  2.2765e-02, -8.5192e-03,  1.6213e-02,  5.7452e-03,\n                         7.3420e-03, -4.3842e-03,  3.3941e-02, -2.5822e-02, -2.8185e-03,\n                         6.1175e-03, -1.2851e-02,  2.2960e-02,  1.2218e-02,  3.1601e-02,\n                        -6.8406e-03, -6.6509e-03, -2.1881e-02,  1.7498e-02, -3.0401e-02,\n                         2.3305e-02,  3.0561e-04,  2.7803e-02, -9.5760e-03, -2.6578e-02,\n                         2.5493e-02, -5.6955e-03,  3.4868e-02,  3.4867e-02, -1.5334e-02,\n                         1.2307e-02,  3.2940e-02, -1.6280e-02,  2.7300e-03,  2.6494e-02,\n                        -2.2274e-02, -3.5916e-02,  3.8977e-03,  2.6565e-02,  1.8804e-02,\n                        -3.5623e-02,  3.8858e-02,  3.9469e-02, -1.2582e-02,  2.0967e-02,\n                         2.6164e-02,  2.7672e-02,  1.3406e-02, -1.9833e-02, -1.5318e-02,\n                         1.8168e-02, -4.1548e-05,  2.3534e-02,  1.6734e-02, -3.9327e-02,\n                        -2.2294e-02, -2.5934e-02,  3.2913e-03, -2.7214e-02,  1.9733e-03,\n                        -3.8162e-02,  1.8287e-02,  3.1213e-02, -2.7818e-02,  8.6202e-03,\n                         3.3974e-02, -1.3465e-03, -3.5463e-02,  4.2807e-04,  3.1432e-02,\n                        -4.0292e-03, -3.5464e-02, -1.7240e-02,  3.4643e-03, -2.8227e-02,\n                        -1.2663e-02,  3.4272e-02,  1.7631e-02,  2.8085e-02, -3.9878e-04,\n                        -6.9640e-03, -2.4297e-02,  1.5934e-03,  2.1039e-02, -1.0240e-02,\n                        -1.3011e-02, -3.9422e-02, -5.9084e-03,  2.0002e-02, -2.3312e-02,\n                        -4.6772e-03, -2.6953e-02, -3.0060e-02, -2.6051e-02, -4.1227e-03,\n                        -3.1632e-02, -3.7831e-02,  1.0201e-02,  1.9551e-02,  1.7001e-03,\n                         2.2559e-02, -1.8918e-02, -3.0103e-02,  4.4304e-03, -1.0413e-02,\n                        -1.5300e-03,  2.3049e-02, -2.7235e-02,  9.6106e-05, -8.6126e-03,\n                        -2.2896e-02,  2.5571e-03,  3.7677e-02, -1.5997e-02,  1.6283e-02,\n                         2.9678e-02,  4.4965e-03, -3.7583e-02,  9.8313e-03,  2.4915e-02,\n                        -1.4751e-02, -2.8991e-02,  7.6184e-03, -1.8814e-02, -6.6200e-04,\n                        -2.0119e-02,  2.6055e-02, -1.6136e-02,  1.3383e-02,  3.1269e-03,\n                         2.9215e-02, -1.4701e-02,  4.8165e-03,  3.0593e-02, -3.5732e-03,\n                         6.7279e-03, -1.8217e-02,  1.9820e-02,  2.7430e-02,  3.8815e-03,\n                         6.8131e-03, -1.2714e-02,  1.4538e-02,  3.9489e-02, -8.0114e-03,\n                        -1.1076e-02,  8.4630e-03,  1.3901e-02,  3.1342e-02, -7.3673e-04,\n                        -3.2897e-02, -2.7446e-03,  1.5289e-02, -2.0702e-02, -1.4422e-02,\n                        -9.2530e-03, -9.7802e-03, -1.4826e-02,  5.3690e-03, -3.5948e-02,\n                         3.2393e-02,  3.0301e-02, -2.3555e-02,  4.3515e-03, -2.0085e-03,\n                        -2.0028e-02, -2.5264e-02,  1.0520e-03,  1.5091e-02, -2.0584e-02,\n                         2.9349e-02, -3.1742e-02,  8.1308e-04,  2.6636e-02, -3.7196e-02,\n                        -3.8569e-02, -1.4778e-03,  1.9633e-02,  2.0384e-02,  3.4024e-03,\n                        -3.0682e-02, -7.7087e-03, -1.2552e-02, -3.1007e-02, -1.5955e-03,\n                         2.2174e-03, -1.7998e-03,  1.1731e-02, -3.9251e-03,  3.6748e-02,\n                         1.0467e-02,  1.3199e-02, -2.6035e-02,  3.5483e-02,  1.7884e-02,\n                        -1.0198e-02,  8.6966e-03,  1.9822e-02, -2.3939e-02,  1.3147e-03,\n                        -2.3703e-02,  4.2465e-02,  9.6293e-03,  6.8498e-03,  2.1037e-02,\n                        -1.4240e-02, -8.9934e-03,  4.2770e-02, -1.6757e-02, -3.1554e-02,\n                         3.5893e-02,  1.5083e-02, -1.0114e-02, -6.9699e-03, -6.8748e-03,\n                         2.5594e-02, -1.6572e-02, -3.3063e-02, -1.4327e-02,  4.1345e-02,\n                         7.7683e-03, -1.8451e-02, -3.6633e-02,  3.0726e-04, -3.3158e-02,\n                        -3.4935e-02, -1.3991e-02]], device='cuda:0')),\n              ('fc_humor.bias', tensor([0.0347], device='cuda:0')),\n              ('fc_sarcasm.weight',\n               tensor([[ 2.7794e-02,  4.2138e-02,  3.0321e-02, -2.1055e-02,  2.3490e-02,\n                        -3.3070e-02, -3.8181e-03, -1.0542e-02,  2.2783e-02,  8.7941e-03,\n                         8.5236e-04, -9.0056e-03, -1.5563e-02,  1.9386e-03, -5.4762e-03,\n                        -8.2069e-03, -1.5392e-02,  1.9014e-02,  1.4945e-03, -1.1021e-03,\n                         3.9713e-02, -2.7680e-02, -3.2604e-02, -6.6039e-03, -1.0554e-02,\n                        -1.0299e-02,  4.2903e-03,  2.6186e-02, -1.2892e-02,  3.9989e-02,\n                         1.9943e-02,  1.3050e-02,  1.7171e-02, -1.1629e-02,  3.9127e-02,\n                        -3.8591e-03,  3.2687e-02, -3.9897e-02, -3.7096e-02,  8.2033e-03,\n                        -2.2028e-02,  2.6309e-02,  2.2658e-02,  2.0664e-02, -1.8102e-02,\n                         1.1737e-02,  3.3929e-02, -4.2431e-02, -4.1198e-02, -3.6439e-02,\n                        -3.6202e-02,  2.5811e-02, -1.2534e-02,  2.0435e-02, -3.7155e-02,\n                         3.2956e-02, -1.3392e-02,  1.5151e-02,  3.0358e-02, -3.6421e-02,\n                        -2.3403e-02,  2.7358e-02,  1.9383e-02,  3.4514e-02, -6.5527e-03,\n                        -1.2570e-02, -1.7868e-02, -3.9899e-02, -2.8102e-02,  1.9117e-02,\n                         3.8337e-02,  3.2951e-02, -2.1824e-02,  1.1434e-02, -3.0818e-02,\n                         2.4694e-03,  2.4882e-02,  3.3721e-02, -3.5172e-02,  3.2591e-02,\n                         1.1356e-02,  1.8674e-02, -1.5925e-02, -1.2285e-03, -4.0729e-02,\n                        -1.8050e-02,  5.5650e-04, -2.8208e-02,  1.1226e-02, -2.0692e-02,\n                        -2.6268e-02, -2.0422e-02, -2.0685e-04,  3.1452e-02, -2.7263e-02,\n                         2.8356e-02, -2.6673e-02, -3.8170e-02, -3.3132e-02,  3.9022e-02,\n                         3.9756e-02,  3.3595e-02, -8.6950e-03, -3.3917e-02, -2.8701e-02,\n                         3.8286e-02, -8.6336e-03, -7.8716e-04, -3.4330e-02,  7.4184e-03,\n                         3.2122e-02,  9.9083e-03, -1.5353e-02,  1.2984e-02, -6.3121e-04,\n                         3.0732e-02, -2.9757e-02,  7.9586e-03,  3.8474e-02,  3.5957e-02,\n                        -2.8525e-02,  2.0292e-02, -2.4272e-02,  3.2683e-02, -3.2276e-02,\n                        -3.3579e-02,  5.1397e-03,  2.2212e-02, -1.2409e-02,  1.7395e-02,\n                         2.2101e-02, -5.0664e-03, -1.3095e-02,  3.4717e-02,  2.4669e-02,\n                        -2.7065e-02, -3.9500e-02,  1.7003e-02,  1.0854e-02,  4.2777e-02,\n                        -3.8690e-02,  3.8051e-02, -3.1084e-02, -1.7330e-02,  1.4082e-03,\n                        -3.8696e-02, -1.8480e-02, -3.4964e-02,  2.7846e-02,  2.7699e-02,\n                         1.2178e-02,  3.6072e-02,  6.1030e-03, -1.9208e-02,  1.7279e-02,\n                        -1.0503e-02,  2.7012e-02, -8.3719e-03,  4.3254e-02, -1.4386e-02,\n                        -1.4889e-02,  7.7719e-03,  1.0998e-03, -1.6083e-02, -2.3488e-02,\n                        -1.4079e-02, -2.9858e-02, -2.0485e-02, -3.0363e-02, -2.6939e-02,\n                        -6.8188e-05,  3.2751e-03, -4.1809e-03,  4.9631e-03,  2.2780e-02,\n                         1.8241e-02,  1.7665e-02, -3.4504e-02, -2.8147e-02,  6.7700e-04,\n                        -4.6074e-02, -7.1462e-03,  2.6920e-03, -3.2533e-02,  3.7215e-02,\n                         2.6790e-02,  2.5847e-02, -1.2200e-02,  5.0452e-03, -3.1539e-02,\n                         1.2747e-02, -3.5489e-02,  1.0668e-04,  3.9000e-02,  3.9578e-02,\n                         2.3604e-02, -1.2152e-02, -1.4696e-02, -3.8852e-02,  3.7312e-02,\n                        -3.3156e-03,  3.6692e-02, -4.0976e-02, -1.6081e-02,  1.8927e-03,\n                         2.5052e-02,  4.1002e-02,  5.8879e-03, -3.0737e-03,  1.5645e-02,\n                         2.0873e-02, -3.3055e-02,  3.6796e-02,  4.2452e-02, -3.9901e-02,\n                        -3.5235e-02,  1.2563e-02,  1.1753e-02, -2.4716e-03, -1.9333e-02,\n                        -4.1541e-02, -2.4544e-02, -3.6834e-02, -2.6377e-02, -1.9607e-02,\n                         2.7673e-02, -2.7127e-02, -4.0423e-02,  3.2882e-03, -4.1661e-02,\n                         5.7443e-03, -2.9040e-03,  3.7948e-02,  2.0590e-02,  2.4112e-02,\n                        -2.9841e-02,  2.0676e-03,  5.8866e-03, -4.4611e-02,  3.0692e-02,\n                        -1.4292e-02, -3.7343e-02,  1.1522e-02, -2.2106e-03,  1.7692e-02,\n                        -1.9330e-02,  4.2448e-02,  2.9249e-02,  3.5688e-02,  2.3576e-02,\n                        -2.5887e-02,  3.6377e-02,  2.6530e-02,  1.7213e-02,  4.2793e-02,\n                        -1.3526e-02,  2.2994e-02, -1.5033e-02,  6.2996e-03, -2.0037e-02,\n                         1.7983e-02, -3.1778e-02, -1.6378e-03, -2.9404e-02,  9.1357e-03,\n                         6.0663e-04, -2.0761e-02,  2.5757e-02,  2.9479e-02,  2.4107e-02,\n                         3.5024e-02, -2.0533e-02,  1.2886e-02,  3.3309e-02,  3.1507e-02,\n                        -3.2831e-02,  3.7125e-02, -2.5781e-02, -4.5719e-03,  3.0961e-02,\n                         2.2456e-03, -1.2087e-02, -1.5185e-02, -1.8236e-02, -2.5248e-02,\n                         2.0237e-02,  1.2469e-02, -9.7311e-03,  8.8748e-03,  1.8810e-02,\n                        -2.9739e-02,  3.2037e-02, -4.9707e-03,  2.9789e-02, -1.9668e-02,\n                        -2.8957e-02,  1.8077e-02,  1.0272e-02,  5.8166e-03, -1.0298e-02,\n                         3.2771e-02, -2.7389e-02,  1.5927e-02,  5.6127e-03,  1.4115e-02,\n                        -3.7437e-02, -1.3439e-02,  5.0893e-03, -1.8836e-02, -1.2971e-04,\n                        -4.1010e-03, -2.3970e-03, -1.5412e-02, -1.4375e-02, -1.9397e-02,\n                        -2.7182e-02, -8.5032e-03,  1.5334e-02, -2.3138e-02,  1.8745e-02,\n                         3.1106e-02,  7.6771e-03, -2.0702e-02,  1.6249e-03,  1.5466e-02,\n                         3.5510e-02, -1.1160e-02, -1.5554e-02,  2.2974e-02, -3.7635e-02,\n                        -1.4731e-02, -3.0390e-02,  4.1821e-02,  3.0721e-02,  3.6842e-03,\n                         1.3658e-02,  3.6258e-02, -2.1154e-02,  4.7920e-04, -3.1127e-02,\n                         1.1503e-02, -9.3371e-03,  1.5491e-02, -9.7512e-03,  6.5689e-03,\n                        -3.5296e-03,  3.3553e-02,  5.5779e-03, -2.7664e-02, -1.9362e-02,\n                        -2.4700e-02,  1.1508e-02,  3.1536e-02,  1.3379e-02, -1.2661e-02,\n                        -1.7791e-03,  2.4306e-02, -1.3650e-02,  2.3531e-02,  2.8177e-02,\n                        -2.8241e-02,  1.7606e-02,  1.0452e-02,  3.4778e-02, -5.1749e-03,\n                         1.5545e-02,  2.2929e-02, -3.9911e-02, -3.9754e-02,  2.7817e-02,\n                         8.1913e-03, -2.3125e-02,  2.0298e-02,  2.4251e-02, -1.6235e-02,\n                        -2.7641e-04,  3.7457e-02, -2.4284e-02,  3.4387e-02, -2.9529e-02,\n                        -1.0028e-03, -7.5812e-03, -3.1608e-02, -1.3303e-02, -3.4747e-02,\n                        -1.5852e-02, -1.1577e-03, -4.2116e-02, -6.6135e-03,  1.1609e-02,\n                        -1.2438e-02, -1.7481e-02, -1.0390e-02,  3.7072e-02,  4.0146e-02,\n                        -6.7334e-04,  1.8648e-02,  1.2438e-02,  3.8123e-02, -2.7058e-02,\n                        -3.7060e-02,  5.1925e-03,  2.7692e-03, -6.8300e-03,  8.7087e-03,\n                         1.8753e-02, -3.7012e-02, -2.5847e-02, -9.0316e-04,  2.9733e-02,\n                         3.8472e-02, -3.1094e-02, -1.6772e-02,  1.7354e-02,  2.9023e-02,\n                        -3.2565e-02,  1.6773e-02, -3.2296e-02, -9.5807e-03,  1.1148e-02,\n                         3.8816e-02,  2.8972e-02,  3.6160e-02, -2.4895e-02,  3.4875e-02,\n                         2.1085e-02,  3.9760e-03,  1.9259e-02, -1.6518e-02, -2.1632e-02,\n                        -2.2829e-02, -4.4302e-03, -3.6358e-03, -9.3429e-03,  1.5542e-02,\n                         5.5325e-03,  2.7679e-02, -7.1438e-03,  2.1991e-03,  3.1630e-02,\n                        -4.1257e-02, -1.3782e-02,  1.3730e-02,  3.2905e-02,  3.0148e-02,\n                         5.8126e-03,  2.4593e-02, -3.3864e-02,  1.3066e-03,  1.5327e-02,\n                         2.4823e-02, -7.0950e-03,  6.5574e-03, -2.2337e-02, -3.8050e-02,\n                         5.5514e-03,  3.8489e-02,  1.5654e-03,  2.7016e-02, -2.0393e-02,\n                         2.2321e-03, -2.5249e-02, -4.2079e-03,  1.9286e-02, -4.1113e-02,\n                         4.2215e-02,  2.2349e-03, -3.2982e-02,  2.2521e-02,  6.0145e-03,\n                         1.5062e-02,  2.5851e-02,  1.0708e-02,  5.6443e-03,  1.0281e-02,\n                         7.2820e-03,  2.2982e-02,  2.2464e-02, -3.5025e-02, -1.1268e-02,\n                         1.8263e-02,  8.0419e-03, -2.6657e-03,  1.7923e-02,  3.3483e-03,\n                        -3.9556e-02,  1.7909e-02,  1.6123e-02, -2.4911e-02, -2.1890e-02,\n                         3.1273e-02,  3.1192e-02,  1.8818e-02, -8.0462e-03,  6.1538e-03,\n                         5.8988e-03, -1.8052e-02,  3.4303e-02, -1.5109e-02,  2.8122e-02,\n                        -2.0348e-02, -1.7107e-02,  6.4872e-03,  4.5850e-04,  3.6706e-02,\n                         1.4327e-02,  5.0611e-03, -3.4484e-02,  2.3657e-02, -4.4622e-02,\n                         1.5507e-02, -1.3614e-02]], device='cuda:0')),\n              ('fc_sarcasm.bias', tensor([0.0176], device='cuda:0')),\n              ('fc_offensive.weight',\n               tensor([[ 1.4928e-02, -5.7986e-03,  3.5240e-02, -1.5520e-02,  9.0820e-03,\n                        -9.5770e-03,  2.0075e-02, -1.5492e-02, -3.2592e-02, -1.6582e-03,\n                        -4.1409e-02,  2.5150e-02, -4.7480e-02,  3.5463e-02,  4.8693e-02,\n                         2.6633e-02, -2.0739e-02, -9.6972e-03, -1.0015e-02,  2.5818e-02,\n                         2.8660e-02,  1.8309e-02,  3.8443e-02, -2.6755e-02, -1.4906e-02,\n                        -1.7225e-02, -4.6978e-03, -3.2464e-02, -9.2948e-03,  2.2224e-02,\n                        -4.5972e-02,  3.6873e-02, -6.3418e-03,  2.0535e-02,  4.4605e-03,\n                         1.8307e-02, -2.5733e-03,  4.1923e-02, -3.5444e-02,  1.3851e-02,\n                        -1.9473e-02, -9.5292e-03,  9.3933e-03, -3.3205e-02, -2.8726e-02,\n                        -2.2500e-03,  3.2322e-02, -1.6478e-02,  4.4883e-02, -2.9710e-02,\n                         4.4890e-03, -3.8270e-02, -2.8741e-02,  7.0070e-03,  1.2659e-02,\n                         1.4950e-02,  2.9857e-02,  1.3692e-02,  1.7103e-03, -4.0059e-02,\n                         3.1260e-02, -2.8329e-02,  4.7929e-02,  3.6804e-02, -3.9714e-02,\n                        -3.8894e-02,  1.8962e-02, -7.3445e-03, -2.1451e-02, -1.8484e-02,\n                         1.2444e-02, -6.5259e-04, -1.7366e-02,  2.8534e-02,  1.3566e-02,\n                         1.0945e-02, -1.3778e-02, -4.0889e-02,  4.3447e-02, -3.0366e-02,\n                        -1.0679e-02,  2.9657e-02, -3.3860e-03, -3.6337e-02,  3.2221e-02,\n                        -9.7373e-03, -2.1464e-02, -3.1097e-03,  4.2258e-02,  1.2205e-03,\n                        -3.4106e-02, -2.0644e-02,  7.2231e-03, -1.7033e-02,  3.6352e-02,\n                         2.9744e-02,  2.4498e-02,  2.6207e-02,  1.4480e-02, -4.5720e-03,\n                        -2.2416e-02,  3.5751e-02, -2.4206e-02,  3.7259e-02,  2.5464e-02,\n                        -1.2122e-02,  3.5894e-02,  1.6303e-02, -4.2180e-02,  1.2647e-02,\n                         2.7228e-02, -2.2655e-02,  2.1965e-02,  1.1112e-02, -7.1716e-03,\n                         5.4776e-03,  4.6113e-02,  1.8007e-02,  2.7004e-02, -3.2315e-02,\n                        -8.2224e-03, -1.2465e-02, -3.7634e-02, -1.3267e-02, -2.9512e-02,\n                         1.3326e-02, -1.6428e-02,  2.6587e-02,  3.5937e-02,  4.5174e-02,\n                        -1.9365e-02,  3.2086e-02,  1.3456e-02,  1.9257e-02, -2.4789e-02,\n                        -1.1215e-02, -3.4710e-02,  3.2756e-02, -2.6040e-02, -2.3256e-02,\n                        -2.8139e-02,  6.0345e-03,  4.9504e-04, -2.0211e-02,  7.9354e-03,\n                        -3.9725e-02, -1.7492e-02, -2.7937e-03,  3.0207e-02,  2.5955e-02,\n                         3.6933e-02, -2.7722e-02,  8.1233e-03, -2.9140e-02,  2.8300e-02,\n                         1.4372e-02,  2.7763e-03,  1.1741e-02, -7.5632e-03,  2.8040e-02,\n                        -1.2143e-02,  1.0336e-03,  1.7766e-02, -2.8274e-02,  4.1605e-02,\n                        -5.1634e-03, -3.0497e-02, -5.1550e-03,  3.8155e-02, -3.5632e-02,\n                         1.8304e-02,  4.1259e-02,  4.3907e-02,  1.9772e-02, -2.4528e-02,\n                        -3.9805e-02,  4.3448e-02, -1.0410e-02,  1.3630e-02,  9.0476e-03,\n                        -3.8393e-02, -3.6980e-02,  1.2511e-02,  1.8840e-02, -2.8125e-03,\n                         7.6011e-03, -3.5221e-02, -3.5708e-02, -5.5035e-03,  8.6119e-04,\n                        -7.7634e-03,  2.8872e-02, -1.0407e-02,  1.0340e-02,  6.1254e-03,\n                        -3.0312e-02, -5.8856e-03, -6.7114e-04,  2.5469e-02, -1.3435e-02,\n                        -1.8849e-02,  2.0889e-02, -3.0474e-02,  3.5316e-02, -1.3078e-02,\n                        -1.9505e-02,  2.9679e-02, -3.3878e-02,  3.1816e-02,  2.9859e-02,\n                        -4.3239e-02,  8.2206e-03,  3.8980e-02, -4.0698e-02,  1.7751e-03,\n                         1.0044e-02,  2.3275e-02, -4.2741e-03,  2.3708e-02,  3.5454e-02,\n                         1.1125e-02, -1.2275e-02, -1.6641e-02,  3.5252e-03, -2.6665e-02,\n                         1.0305e-02,  1.8045e-02,  9.3837e-03,  3.1337e-02, -2.6083e-02,\n                         3.0523e-02, -1.2381e-02,  2.3543e-02, -7.9438e-03,  3.9995e-02,\n                         3.8852e-02, -2.7002e-02,  3.9193e-02, -4.1975e-02,  1.7633e-02,\n                        -5.9606e-03, -2.7357e-02,  4.1088e-02, -2.5360e-02, -8.6689e-03,\n                        -5.7172e-03,  7.1988e-03,  4.0027e-02, -2.9847e-02,  3.8616e-02,\n                        -2.7566e-02,  1.3257e-02, -3.9824e-02, -2.5254e-02,  3.5298e-02,\n                        -2.7500e-03,  5.3494e-03,  1.2744e-02,  2.2142e-02,  3.4685e-02,\n                        -4.2257e-03, -9.1266e-03, -2.4601e-02,  2.5936e-02, -2.1336e-03,\n                         3.1469e-02,  1.1633e-02, -2.8232e-02, -5.3441e-03,  3.3826e-02,\n                        -7.2494e-03, -1.6403e-02, -1.9509e-02,  2.3572e-02,  3.4725e-02,\n                         2.8643e-02,  3.1952e-02,  2.2034e-02,  2.8563e-02, -1.3839e-02,\n                         2.3445e-02,  1.7363e-02, -1.3132e-02,  1.8923e-02, -2.8027e-03,\n                         3.5033e-02,  3.7191e-02, -2.3428e-02, -3.6503e-02,  3.4082e-02,\n                        -2.9085e-02, -2.5677e-02,  4.2481e-02,  4.0129e-02, -1.9220e-02,\n                         2.5430e-02,  2.4317e-02, -3.1151e-02, -7.5832e-03, -2.4064e-03,\n                        -8.8827e-03, -1.4542e-02, -1.2786e-02, -3.3192e-02,  1.3327e-02,\n                        -1.2829e-02, -3.1909e-02,  1.9474e-03,  6.6229e-03, -1.3859e-02,\n                        -9.8526e-03,  5.9117e-03, -2.7317e-02, -5.1692e-03, -2.6738e-02,\n                         1.8244e-02,  4.6283e-03, -2.5553e-02, -1.6334e-03,  1.7662e-02,\n                        -1.4087e-03, -2.2403e-02,  6.1987e-03,  1.5422e-02, -3.3756e-02,\n                         3.3769e-02,  3.6659e-02,  4.8914e-03,  1.0883e-02,  3.5873e-02,\n                         2.0376e-02,  7.5042e-03, -2.5575e-03, -2.9014e-02,  2.3904e-03,\n                        -2.3775e-02, -3.6347e-02,  1.3296e-02,  3.3630e-02,  2.2073e-02,\n                        -2.0368e-02, -3.8337e-02, -2.3553e-03, -2.7254e-02, -3.7769e-02,\n                         1.6461e-02, -2.0255e-02, -1.5894e-02,  2.5096e-03, -3.6902e-03,\n                         2.5076e-02,  3.4183e-02,  1.4876e-02,  1.9367e-02,  3.5157e-02,\n                         2.8374e-02, -1.1178e-02,  3.7007e-02, -1.6830e-02, -1.4094e-02,\n                        -3.1094e-02, -1.7370e-02,  7.5588e-03, -3.5967e-03, -2.0622e-02,\n                         3.4401e-02,  3.9360e-02, -1.9516e-02,  3.2556e-02, -2.4847e-02,\n                         3.6566e-03,  2.1913e-02, -1.6068e-02,  1.6010e-02,  3.7078e-02,\n                        -1.4375e-02,  3.6259e-02,  2.9934e-02, -1.4458e-02,  4.2554e-02,\n                         1.9306e-03, -3.5727e-02,  1.7506e-02, -7.1691e-05, -4.0623e-02,\n                        -1.6710e-02, -1.8472e-02,  3.2129e-02,  1.2942e-02,  9.4330e-03,\n                        -3.4475e-03,  2.8378e-02, -1.1236e-03, -2.9090e-02, -1.4319e-02,\n                         1.2249e-02, -1.1829e-02,  3.0318e-02,  2.7513e-02, -2.0657e-02,\n                        -2.6287e-02, -1.1190e-03,  3.8090e-03, -1.2771e-02,  2.4313e-02,\n                         3.8707e-04, -2.4507e-02,  9.2182e-03,  1.7698e-02,  4.0750e-02,\n                         2.0366e-02, -3.4560e-02,  3.2531e-02, -2.3790e-02, -1.3913e-02,\n                         4.1407e-02, -3.6622e-02,  3.1468e-02, -4.3214e-02,  3.4380e-02,\n                        -3.2211e-02,  2.4034e-02,  3.3871e-02,  2.2694e-02, -2.7474e-02,\n                        -4.8479e-03,  1.6720e-02, -1.2280e-03, -2.8022e-02,  1.5018e-02,\n                         2.4941e-02,  3.1363e-02,  9.4868e-03, -2.9490e-02,  3.8185e-02,\n                         2.4095e-02, -8.8287e-05, -4.0613e-02, -3.6151e-02,  2.2002e-03,\n                         1.8213e-02,  3.8650e-02, -8.8738e-03, -3.4988e-02, -1.0407e-02,\n                        -3.8092e-03,  2.6636e-02,  2.7394e-02, -6.7361e-03, -2.2509e-02,\n                        -8.3383e-03, -9.8769e-03, -3.2377e-02,  2.4699e-03, -4.6871e-03,\n                        -1.8712e-02, -5.5709e-03, -4.2241e-03, -4.0851e-02, -8.6151e-04,\n                        -1.6513e-02, -7.9424e-03,  1.3243e-02,  1.8195e-02,  6.0482e-03,\n                         2.2345e-02,  8.1184e-03,  1.5244e-02, -3.5722e-02,  3.1228e-02,\n                        -2.8703e-02,  2.5366e-02, -3.6726e-02, -2.0997e-02,  4.3337e-02,\n                        -6.1449e-03,  2.0765e-02, -1.7044e-02,  4.1166e-03,  4.2555e-02,\n                        -1.6145e-03, -6.2412e-03, -7.3439e-03,  3.7692e-02,  2.7710e-03,\n                        -1.3172e-02,  1.5032e-02,  2.6548e-02,  3.9175e-02,  6.4244e-03,\n                         1.0167e-02, -2.7950e-02, -3.4065e-02, -9.3098e-03, -4.1057e-02,\n                         4.0665e-02, -2.1600e-02, -2.3411e-02,  1.0776e-02, -9.4404e-03,\n                        -2.2834e-02,  3.0773e-02, -2.3957e-02, -1.6673e-02, -4.1998e-02,\n                         1.9469e-02,  3.5133e-02, -4.2425e-02,  2.5142e-03, -3.6710e-02,\n                        -2.2488e-02, -3.9337e-02]], device='cuda:0')),\n              ('fc_offensive.bias', tensor([0.0092], device='cuda:0'))]),\n 'optimizer_state_dict': {'state': {0: {'step': tensor(1750.),\n    'exp_avg': tensor([[ 3.8900e-04,  9.2656e-04,  1.6700e-03,  6.3135e-03, -3.6361e-03,\n              3.7558e-03, -1.7225e-03, -9.1016e-03,  2.5944e-03, -3.3250e-03,\n              5.8022e-04, -1.4886e-03, -2.7920e-03,  1.0180e-03,  1.4924e-03,\n             -6.8067e-03,  4.1989e-03, -1.4691e-03,  2.8677e-03, -4.2119e-04,\n              9.5272e-04, -2.1777e-03,  1.7287e-03, -7.9750e-04,  3.3608e-04,\n              1.8198e-03,  1.7807e-03, -2.0903e-03, -1.5053e-03,  1.7181e-03,\n              8.8022e-04,  1.8865e-05, -7.5716e-05, -2.1311e-03,  7.2898e-04,\n              1.8014e-03,  1.1792e-03,  1.0628e-03, -1.7900e-04, -1.5881e-04,\n              2.5417e-04, -1.8040e-03, -1.6028e-03, -6.6181e-04, -1.9270e-04,\n             -1.1040e-03,  1.5202e-04,  2.6201e-03, -2.6630e-04, -8.2950e-04,\n              3.9102e-03, -1.1655e-03,  8.6752e-04, -9.0137e-04, -1.9673e-03,\n              5.4099e-04, -1.4998e-03,  1.0389e-03,  3.4624e-04, -2.1747e-04,\n             -3.1163e-04, -2.3065e-03,  1.2314e-03,  2.4507e-03, -1.0356e-03,\n             -1.5717e-04, -7.1026e-04,  7.4342e-04,  1.3063e-03, -3.8510e-04,\n              2.0377e-03,  1.0890e-05,  1.1671e-04, -4.1067e-05, -3.5596e-04,\n              5.7738e-04, -1.6720e-04, -1.6405e-03,  1.1573e-03,  6.7450e-04,\n              9.2222e-04,  2.9446e-04,  7.8701e-04, -1.4986e-03,  2.3682e-04,\n             -1.4501e-03, -1.2011e-04, -1.3523e-03,  8.1889e-04,  9.1786e-04,\n              9.4289e-04,  4.1359e-04,  2.4791e-03, -8.1155e-04,  4.0708e-04,\n              1.3967e-04, -4.7254e-04, -1.5406e-03,  4.2578e-04, -4.2960e-04,\n              3.5016e-04, -6.8596e-04,  1.3759e-03,  3.4728e-04, -2.1369e-03,\n              3.4964e-04,  1.2344e-04,  1.1024e-03, -5.7215e-04,  2.8852e-04,\n              7.1199e-04,  3.0181e-04, -7.3372e-04, -1.1586e-04, -1.1561e-03,\n              1.3507e-03, -2.4189e-04,  4.9474e-04, -1.9555e-04, -6.5083e-04,\n             -1.0573e-03,  1.2113e-03,  2.9415e-04,  2.5253e-04,  7.0802e-04,\n              2.1118e-04,  6.7066e-05,  1.2791e-03, -1.2085e-03,  1.4514e-03,\n              6.8369e-04, -1.8806e-04, -1.4302e-03,  3.6600e-04, -5.8161e-05,\n             -1.0072e-03,  8.2916e-04,  3.7860e-04,  3.2003e-04, -9.5011e-05,\n              1.1823e-04,  1.3938e-03, -1.5534e-03,  5.3265e-05, -6.5323e-04,\n              4.2524e-04,  2.6021e-06, -3.4195e-05,  3.9408e-04, -9.6578e-04,\n             -5.4082e-04,  9.5240e-06, -6.5531e-04,  8.8318e-04, -8.8179e-04,\n             -7.1581e-04, -5.9311e-04, -4.3559e-04, -9.9496e-04,  6.0697e-04,\n             -5.3242e-04,  1.0371e-03, -4.8570e-04,  4.0650e-04, -6.6390e-04,\n             -5.8889e-04,  3.7024e-04, -6.6597e-05,  4.2913e-04, -3.6322e-05,\n              8.2698e-05, -2.1523e-04, -4.3360e-04, -7.0773e-04,  1.8908e-04,\n              7.5416e-04,  1.1017e-04, -8.7259e-04,  3.5404e-04,  9.3292e-04,\n             -2.7557e-04, -9.0714e-05, -2.0860e-04, -1.8975e-04, -2.2232e-04,\n             -2.8552e-04, -3.9194e-04, -9.1231e-04,  4.5604e-04, -2.5605e-04,\n              9.8385e-05, -2.2925e-04, -7.1602e-04,  8.8801e-05,  4.4873e-04,\n              7.2574e-04,  5.2417e-04, -6.1472e-05,  8.6903e-04, -4.4570e-04,\n             -1.7748e-04, -1.6230e-04,  6.9106e-04, -2.5703e-04,  9.6717e-05,\n             -1.0633e-03, -1.1815e-03, -4.4195e-04,  1.1539e-03,  4.2427e-04,\n             -1.9083e-06, -1.4005e-04, -5.7552e-04,  2.2287e-04,  4.4731e-04,\n              5.7873e-05,  2.3673e-04,  8.4507e-04, -1.3327e-04, -2.1129e-05,\n             -8.9708e-04,  5.1454e-04, -5.9383e-04, -1.0476e-04, -4.8923e-04,\n             -4.7019e-04,  3.8159e-04, -8.5708e-05,  6.6493e-04,  6.4986e-04,\n              4.7169e-04, -3.6061e-05,  8.9947e-04, -5.4652e-04, -7.0882e-04,\n             -9.2274e-04,  4.7473e-04,  3.1853e-04,  5.9264e-04,  6.9203e-04,\n              4.6901e-04,  1.9105e-04, -2.8058e-04, -2.8603e-04,  3.4378e-04,\n              7.6214e-05, -3.0128e-04,  7.5140e-05,  2.2626e-04,  3.4217e-04,\n             -1.3036e-04, -2.2139e-04, -5.4934e-04, -5.0757e-05,  5.9010e-04,\n             -1.6819e-04,  9.0358e-02, -7.4654e-02, -3.4625e-02, -1.1032e-02,\n              4.3993e-02,  2.6269e-02,  1.3800e-02, -1.9042e-02, -3.1137e-02,\n              5.8432e-03, -4.4280e-03,  9.4374e-03, -4.0006e-02,  2.2806e-02,\n             -1.8795e-02, -2.2530e-02, -4.5517e-03, -3.7916e-03, -3.4804e-02,\n              5.7160e-03, -8.4888e-03,  2.8163e-02, -1.1849e-02,  1.1385e-02,\n             -8.0883e-04,  1.2645e-02, -2.9054e-02,  3.3849e-02,  1.5593e-04,\n             -5.2758e-03,  8.6436e-03, -4.7663e-03,  4.3135e-03, -1.0572e-02,\n             -1.4985e-02,  9.4339e-03,  1.8504e-03, -2.2032e-02,  9.6275e-03,\n              9.8986e-04, -9.8465e-03,  1.9675e-02, -1.8485e-02,  9.1217e-03,\n             -1.6270e-02, -1.1958e-02, -2.9055e-03,  5.9453e-03,  1.0785e-03,\n             -9.7229e-03,  1.9955e-03,  1.4764e-02, -1.7369e-02, -1.4983e-02,\n             -7.3398e-04, -6.7192e-03,  4.0159e-03,  2.2224e-02,  1.8299e-03,\n              7.3029e-03, -1.2184e-02, -1.7323e-02,  7.8848e-03, -8.3427e-03,\n             -1.8714e-02, -4.2689e-03,  1.6122e-02, -6.5209e-04,  5.4619e-03,\n              3.7754e-03, -2.6778e-03, -1.0188e-03, -1.2500e-02,  1.8290e-02,\n              1.2229e-03,  3.2832e-03,  1.0025e-02,  1.6736e-03, -1.2818e-02,\n             -1.7869e-03,  1.0111e-02, -3.7333e-03,  1.0041e-02,  5.3985e-03,\n             -6.3937e-03, -5.2372e-03, -1.0612e-02,  7.3875e-03,  3.3723e-03,\n             -7.4216e-03,  9.3322e-03, -1.6566e-03, -2.1899e-04, -6.7259e-03,\n             -1.3226e-02,  1.6505e-03, -7.3938e-03, -6.1520e-03,  4.7811e-03,\n              1.3242e-03, -9.3526e-03, -9.9443e-03,  9.2956e-03,  2.5431e-03,\n             -2.9831e-03,  3.8825e-03,  2.8976e-03,  2.2428e-03,  1.7497e-03,\n             -6.1645e-03, -3.6910e-05,  3.9092e-03, -3.6991e-04, -9.2301e-03,\n             -3.1126e-03,  2.9945e-03,  1.3521e-03,  7.7031e-03, -2.0211e-03,\n             -8.9240e-03, -3.2393e-03, -9.2592e-03,  9.2265e-03,  5.5883e-03,\n              1.0624e-03,  1.0614e-04, -5.8738e-03, -7.8389e-04, -6.5392e-03,\n              8.4136e-04, -2.7769e-03,  4.1402e-03, -3.8050e-03, -4.2127e-03,\n              1.7411e-03,  6.7880e-03,  1.9936e-03, -9.3298e-04,  3.6502e-03,\n             -2.7772e-03,  1.0717e-02,  4.6099e-03, -6.8859e-03, -4.0012e-03,\n             -9.1033e-03,  1.9688e-03,  4.2385e-03, -4.3865e-03, -4.9858e-03,\n              4.6922e-03, -6.3862e-03, -6.6949e-03, -7.6370e-03, -8.0037e-03,\n             -1.0057e-02, -7.3309e-03, -8.6279e-03,  1.1614e-02, -4.4138e-03,\n             -2.3296e-03,  1.5575e-03,  1.0800e-02,  9.6200e-03,  6.1373e-03,\n             -3.9141e-03, -7.6887e-03, -4.3018e-04,  4.5506e-04,  6.1450e-03,\n             -8.3268e-03,  1.2711e-03, -2.0547e-03, -1.9654e-03,  7.2344e-03,\n              1.0287e-03,  3.0968e-04,  7.2889e-04,  1.1819e-03,  1.9551e-03,\n             -1.8417e-03, -8.3331e-03,  6.1578e-03, -1.5054e-03,  4.7306e-03,\n             -5.3380e-04, -8.6299e-03,  4.3662e-03,  2.9670e-04, -4.9552e-03,\n              6.1475e-05,  6.3310e-03, -2.6730e-03, -4.8694e-03,  5.6912e-03,\n             -1.8326e-03, -2.2471e-03, -3.8185e-03,  6.7923e-03, -1.8538e-03,\n              7.9962e-03, -1.4361e-03,  7.6486e-03, -2.5944e-03, -2.7250e-03,\n             -5.5081e-03,  4.2719e-03, -4.9528e-03, -2.7202e-03,  5.9543e-03,\n             -6.4020e-03, -5.4641e-03, -1.5569e-03, -3.1099e-03,  4.8693e-03,\n              6.3829e-03,  3.8319e-03, -5.9793e-04,  1.5544e-03, -1.5100e-04,\n              2.2084e-03, -9.3222e-03,  1.1617e-03,  6.9452e-03, -1.6214e-03,\n             -3.9066e-03,  1.8663e-03,  3.3062e-03,  8.7439e-03, -2.6627e-03,\n             -2.0594e-04,  3.9438e-04, -7.4218e-04, -4.6931e-03,  6.0375e-05,\n             -7.6025e-04,  4.9937e-03,  3.2923e-03, -1.0494e-03,  3.5361e-03,\n             -1.7200e-04, -4.5549e-03, -1.5399e-03, -4.2149e-03,  1.4171e-03,\n             -6.3503e-04,  7.5222e-04, -3.9849e-03,  3.9377e-05, -6.3148e-04,\n              3.2349e-04, -8.9740e-03, -5.2861e-03, -9.2437e-05, -2.2130e-03,\n             -5.3399e-03, -4.2690e-03]], device='cuda:0'),\n    'exp_avg_sq': tensor([[2.3760e-03, 8.1065e-04, 4.9309e-04, 3.9012e-04, 3.0290e-04, 2.7663e-04,\n             2.4597e-04, 2.2464e-04, 1.8800e-04, 1.5765e-04, 1.6072e-04, 1.3781e-04,\n             1.2497e-04, 1.3162e-04, 1.2418e-04, 1.0582e-04, 9.2845e-05, 9.6305e-05,\n             8.0683e-05, 8.0688e-05, 7.5177e-05, 6.6915e-05, 6.7309e-05, 6.4907e-05,\n             6.7121e-05, 5.7577e-05, 6.1923e-05, 5.3826e-05, 5.6778e-05, 5.5829e-05,\n             5.2147e-05, 4.7358e-05, 4.9472e-05, 4.3766e-05, 4.4719e-05, 4.7148e-05,\n             4.0221e-05, 4.0147e-05, 3.8840e-05, 3.9919e-05, 3.6822e-05, 3.5179e-05,\n             3.7923e-05, 3.6816e-05, 3.6000e-05, 3.4748e-05, 3.4024e-05, 3.3870e-05,\n             3.1380e-05, 3.1161e-05, 3.2698e-05, 2.9354e-05, 2.7836e-05, 2.8152e-05,\n             2.7487e-05, 2.7182e-05, 2.5828e-05, 2.4803e-05, 2.4091e-05, 2.5212e-05,\n             2.4745e-05, 2.3914e-05, 2.4385e-05, 2.2211e-05, 2.2766e-05, 2.1402e-05,\n             2.0913e-05, 2.0849e-05, 2.1085e-05, 2.0478e-05, 2.0347e-05, 1.9599e-05,\n             1.8251e-05, 1.9437e-05, 1.8700e-05, 1.9811e-05, 1.6819e-05, 1.8585e-05,\n             1.8400e-05, 1.7212e-05, 1.6287e-05, 1.7012e-05, 1.6899e-05, 1.6644e-05,\n             1.5500e-05, 1.5978e-05, 1.5836e-05, 1.5002e-05, 1.5196e-05, 1.4795e-05,\n             1.4321e-05, 1.4303e-05, 1.4953e-05, 1.4249e-05, 1.3059e-05, 1.3250e-05,\n             1.2117e-05, 1.3457e-05, 1.2332e-05, 1.2116e-05, 1.3035e-05, 1.2321e-05,\n             1.2257e-05, 1.1507e-05, 1.1891e-05, 1.1203e-05, 1.0975e-05, 1.0259e-05,\n             1.0840e-05, 1.1059e-05, 1.0220e-05, 1.0705e-05, 1.0672e-05, 9.5578e-06,\n             1.0619e-05, 9.2377e-06, 9.4639e-06, 9.7362e-06, 9.2711e-06, 9.8403e-06,\n             9.8835e-06, 8.8195e-06, 8.9894e-06, 9.2728e-06, 9.0413e-06, 9.0689e-06,\n             8.6707e-06, 8.7875e-06, 8.2709e-06, 8.7828e-06, 8.6843e-06, 7.8223e-06,\n             8.0692e-06, 7.8828e-06, 8.4211e-06, 7.4522e-06, 7.4937e-06, 7.0595e-06,\n             7.5119e-06, 7.2799e-06, 7.3654e-06, 7.4498e-06, 7.3436e-06, 7.2185e-06,\n             6.9178e-06, 6.6816e-06, 6.6476e-06, 7.4710e-06, 7.1976e-06, 6.0681e-06,\n             6.6433e-06, 6.6206e-06, 6.4611e-06, 6.5399e-06, 6.2444e-06, 6.1867e-06,\n             6.4060e-06, 6.0265e-06, 5.4638e-06, 5.6884e-06, 6.3913e-06, 6.1328e-06,\n             5.8140e-06, 5.4453e-06, 5.6332e-06, 5.5466e-06, 5.1812e-06, 5.5542e-06,\n             5.4329e-06, 5.4387e-06, 5.0346e-06, 4.9625e-06, 4.7444e-06, 5.0728e-06,\n             5.3141e-06, 4.8716e-06, 5.1573e-06, 4.8555e-06, 4.6677e-06, 4.7961e-06,\n             4.6715e-06, 4.3758e-06, 4.6776e-06, 4.6772e-06, 4.3720e-06, 4.2962e-06,\n             4.1782e-06, 4.6344e-06, 4.3714e-06, 4.1314e-06, 4.1972e-06, 4.2045e-06,\n             4.0671e-06, 3.9780e-06, 4.1941e-06, 3.9998e-06, 3.7912e-06, 4.0112e-06,\n             3.8990e-06, 3.6473e-06, 3.5245e-06, 3.9659e-06, 3.8082e-06, 3.5573e-06,\n             3.6374e-06, 3.7229e-06, 3.8867e-06, 3.7150e-06, 3.6403e-06, 3.7410e-06,\n             3.4738e-06, 3.3664e-06, 3.4879e-06, 3.4058e-06, 3.4764e-06, 3.2543e-06,\n             3.1279e-06, 3.2182e-06, 3.3202e-06, 3.2929e-06, 3.0383e-06, 3.1718e-06,\n             2.9146e-06, 3.0425e-06, 2.9046e-06, 2.8882e-06, 2.9834e-06, 2.7224e-06,\n             3.0041e-06, 2.7364e-06, 2.6395e-06, 2.8123e-06, 2.9248e-06, 2.8503e-06,\n             2.8422e-06, 2.9408e-06, 2.6257e-06, 2.6935e-06, 2.6185e-06, 2.7285e-06,\n             2.5155e-06, 2.6002e-06, 2.5125e-06, 2.4612e-06, 2.5412e-06, 2.3206e-06,\n             2.2912e-06, 2.3884e-06, 2.5344e-06, 2.4556e-06, 2.4141e-06, 2.4709e-06,\n             2.3373e-06, 2.3023e-06, 2.1840e-06, 2.1095e-06, 2.1139e-02, 1.6889e-02,\n             1.1924e-02, 8.7418e-03, 7.1676e-03, 6.2889e-03, 6.0479e-03, 6.0758e-03,\n             5.8131e-03, 4.7201e-03, 5.1951e-03, 4.4130e-03, 3.9130e-03, 3.9770e-03,\n             3.4902e-03, 3.6278e-03, 3.3698e-03, 3.2589e-03, 3.0557e-03, 3.0638e-03,\n             2.5592e-03, 2.7220e-03, 2.3838e-03, 2.3654e-03, 2.2790e-03, 2.3672e-03,\n             2.3736e-03, 2.2327e-03, 2.0195e-03, 2.1100e-03, 2.1214e-03, 1.8385e-03,\n             1.6901e-03, 1.7143e-03, 1.8452e-03, 1.7688e-03, 1.7162e-03, 1.6735e-03,\n             1.6299e-03, 1.6118e-03, 1.4974e-03, 1.6120e-03, 1.3766e-03, 1.3988e-03,\n             1.3978e-03, 1.4419e-03, 1.3209e-03, 1.2358e-03, 1.3025e-03, 1.3463e-03,\n             1.2450e-03, 1.2471e-03, 1.1929e-03, 1.2548e-03, 1.2389e-03, 1.1431e-03,\n             1.0873e-03, 1.2526e-03, 1.0582e-03, 1.0740e-03, 1.1636e-03, 1.0692e-03,\n             1.1004e-03, 1.0556e-03, 1.0283e-03, 1.0532e-03, 9.9274e-04, 9.8059e-04,\n             9.9989e-04, 9.9440e-04, 9.4711e-04, 8.9574e-04, 8.4020e-04, 9.0797e-04,\n             8.7700e-04, 8.5942e-04, 9.3356e-04, 8.6951e-04, 8.4812e-04, 8.5128e-04,\n             8.9239e-04, 8.6074e-04, 8.0131e-04, 8.9123e-04, 7.5938e-04, 7.3913e-04,\n             8.3261e-04, 7.6842e-04, 7.7328e-04, 7.5621e-04, 7.6100e-04, 7.3907e-04,\n             7.5423e-04, 7.1765e-04, 7.6512e-04, 7.2767e-04, 7.2000e-04, 6.6796e-04,\n             7.5615e-04, 6.5119e-04, 6.3273e-04, 7.0260e-04, 6.6979e-04, 6.6752e-04,\n             7.0407e-04, 6.4835e-04, 6.3721e-04, 6.3140e-04, 6.7095e-04, 6.5940e-04,\n             6.3331e-04, 6.1963e-04, 6.4055e-04, 5.8811e-04, 5.7497e-04, 5.9862e-04,\n             5.9886e-04, 6.1120e-04, 6.0625e-04, 5.7997e-04, 5.7106e-04, 5.8958e-04,\n             5.7574e-04, 5.7470e-04, 5.7356e-04, 5.2959e-04, 5.5662e-04, 5.5748e-04,\n             5.8624e-04, 5.4910e-04, 5.0996e-04, 5.4256e-04, 5.7962e-04, 5.3081e-04,\n             5.0061e-04, 5.2840e-04, 5.1667e-04, 4.9505e-04, 5.5644e-04, 5.2134e-04,\n             4.9891e-04, 5.2747e-04, 5.1613e-04, 5.1729e-04, 4.8900e-04, 5.1160e-04,\n             5.1370e-04, 4.4760e-04, 4.8547e-04, 4.6837e-04, 4.8044e-04, 4.9579e-04,\n             4.9490e-04, 4.6322e-04, 4.9470e-04, 4.6559e-04, 4.6434e-04, 4.7370e-04,\n             4.5967e-04, 4.4888e-04, 4.4971e-04, 4.5901e-04, 4.1390e-04, 4.1278e-04,\n             4.5984e-04, 4.3840e-04, 4.7238e-04, 4.1153e-04, 3.9741e-04, 4.1855e-04,\n             4.0668e-04, 4.1471e-04, 4.0579e-04, 4.0680e-04, 4.1182e-04, 4.0946e-04,\n             4.0354e-04, 3.8741e-04, 4.0357e-04, 3.8657e-04, 3.4238e-04, 3.7527e-04,\n             3.9128e-04, 3.8355e-04, 3.9335e-04, 3.8411e-04, 3.6498e-04, 3.8784e-04,\n             3.5920e-04, 3.7841e-04, 3.7315e-04, 3.8418e-04, 3.7658e-04, 3.8516e-04,\n             3.4800e-04, 3.6746e-04, 3.5355e-04, 3.4754e-04, 3.5009e-04, 3.3879e-04,\n             3.7808e-04, 3.7028e-04, 3.6022e-04, 3.6381e-04, 3.3812e-04, 3.5481e-04,\n             3.6131e-04, 3.3700e-04, 3.3147e-04, 3.4498e-04, 3.3172e-04, 3.1613e-04,\n             3.1941e-04, 3.4192e-04, 3.4362e-04, 3.3448e-04, 3.1670e-04, 3.4977e-04,\n             3.3572e-04, 3.0605e-04, 3.2052e-04, 3.1479e-04, 2.9058e-04, 3.1639e-04,\n             2.9528e-04, 2.8469e-04, 3.1052e-04, 3.1646e-04, 2.6996e-04, 3.0718e-04,\n             2.8902e-04, 2.8016e-04, 2.7571e-04, 2.8325e-04, 3.1635e-04, 2.6914e-04,\n             2.6887e-04, 2.7288e-04, 2.8919e-04, 2.8800e-04, 2.6651e-04, 2.7804e-04,\n             2.7985e-04, 2.6342e-04, 2.7180e-04, 2.6537e-04, 2.5668e-04, 2.5304e-04,\n             2.7741e-04, 2.5703e-04, 2.7194e-04, 2.5895e-04, 2.7261e-04, 2.5498e-04,\n             2.6106e-04, 2.6775e-04]], device='cuda:0')},\n   1: {'step': tensor(1750.),\n    'exp_avg': tensor([-0.0980], device='cuda:0'),\n    'exp_avg_sq': tensor([0.0067], device='cuda:0')},\n   2: {'step': tensor(1750.),\n    'exp_avg': tensor([[ 2.8646e-03,  3.5298e-03,  4.4313e-03,  5.1589e-03, -1.6682e-03,\n             -3.0335e-03,  2.2087e-04, -3.1168e-03, -2.2519e-03,  1.0126e-03,\n             -4.5501e-03, -1.4594e-03, -3.0569e-03, -2.5467e-03, -1.5126e-03,\n             -1.4054e-03, -2.6559e-03, -3.9376e-03, -2.0885e-03, -2.2308e-03,\n             -1.6743e-03, -3.1649e-04, -1.0890e-03, -2.3972e-03,  4.0200e-03,\n              3.7951e-03, -5.3160e-05,  1.9894e-03, -1.4794e-03,  1.7203e-03,\n             -8.2379e-04, -3.3593e-03, -1.6000e-03, -1.3284e-03,  1.7797e-03,\n              1.7112e-03,  1.3320e-03, -8.7707e-04, -1.5809e-03, -8.3527e-04,\n              2.1374e-04, -1.5139e-03,  1.3374e-03, -9.9542e-04,  2.6514e-03,\n              4.7694e-04,  9.9395e-04,  2.4487e-03, -3.1877e-04, -1.7404e-04,\n              2.2855e-03,  2.4560e-04,  7.3314e-04, -8.0411e-04, -8.4191e-04,\n              6.9058e-04,  4.5267e-04,  2.6322e-03, -1.2576e-03,  4.6113e-05,\n             -7.8414e-04,  1.8138e-04,  1.1293e-03,  1.7100e-03, -3.4903e-04,\n              1.2291e-03, -1.1313e-03, -8.5386e-04,  1.3445e-03, -1.8092e-03,\n              1.3383e-03,  6.4843e-04, -3.6348e-04,  6.8876e-04, -1.2873e-03,\n             -2.7234e-04, -7.4706e-05, -4.5964e-04,  1.5882e-03,  7.5945e-04,\n              9.6761e-04, -1.9092e-05,  1.4594e-04, -9.6235e-04,  4.9028e-04,\n             -7.0942e-04, -7.1808e-05, -2.0744e-03, -1.6440e-04,  6.1064e-04,\n             -1.7263e-03,  8.8722e-05,  8.5323e-04, -2.9443e-04, -3.5151e-04,\n             -1.8313e-03,  6.4760e-04, -8.9366e-04,  8.1945e-04, -6.6796e-04,\n             -9.8870e-04, -2.1996e-04,  1.4197e-03,  8.1404e-05,  7.2378e-04,\n              1.1935e-03,  8.1081e-04,  1.1155e-03,  2.4958e-04, -7.6487e-04,\n              4.9820e-04,  1.1158e-03,  1.6811e-03,  9.7455e-04,  3.7208e-05,\n             -2.1238e-04, -1.4789e-03,  6.7851e-04, -3.6766e-04,  2.2131e-04,\n              3.3809e-04,  4.5788e-04, -6.0885e-04,  1.3177e-03,  4.2178e-05,\n             -1.7006e-04, -2.9265e-04,  2.1839e-04, -7.7164e-04,  2.1227e-03,\n              7.4956e-04, -7.4244e-04, -2.2693e-04,  5.1761e-05, -3.8316e-04,\n             -5.1417e-04,  3.2211e-04,  3.7856e-04, -1.2131e-03, -4.8207e-04,\n              2.9987e-04,  9.1075e-04, -5.2828e-04, -8.0075e-04,  9.3811e-04,\n             -2.7101e-04, -1.2498e-04,  5.2371e-04,  8.0429e-04, -9.1414e-05,\n             -5.8842e-04,  2.8579e-04, -2.5044e-04, -4.9305e-04, -8.8981e-04,\n             -2.5283e-04,  5.0353e-05, -2.5592e-04, -1.4402e-03, -1.0146e-04,\n             -1.1939e-03,  6.9920e-04, -7.7816e-04,  9.2649e-04, -9.4969e-04,\n              2.5717e-04, -9.5374e-06,  5.1577e-04,  6.7121e-04, -9.5481e-05,\n              3.7491e-04, -3.5636e-04, -4.4509e-04,  6.7454e-04,  9.0090e-04,\n              8.4522e-05, -2.5859e-04,  5.2051e-04,  8.8729e-04,  8.7251e-04,\n              6.0198e-04, -5.1264e-04, -1.1447e-04,  2.9128e-04, -6.6731e-04,\n              4.2464e-04,  1.0682e-03,  4.2785e-04, -5.0053e-04,  6.8252e-06,\n              1.0577e-03,  1.2958e-05, -3.5783e-04, -3.1412e-04,  3.0784e-04,\n              4.2225e-04, -1.8809e-04,  7.1166e-04, -2.7508e-05, -3.9894e-04,\n              3.5017e-04,  5.6908e-05,  5.7395e-04,  3.3301e-04, -1.7027e-04,\n             -6.9910e-04, -8.6454e-04,  1.5829e-04,  1.1986e-03, -1.0518e-05,\n             -2.7097e-04,  3.5742e-05, -1.0322e-03,  9.8307e-05, -4.8924e-04,\n             -1.8860e-04, -3.1322e-04,  5.4099e-04, -2.0137e-04,  2.8944e-04,\n             -3.6313e-04, -4.3348e-04,  2.7286e-05,  8.7590e-05, -1.4104e-05,\n             -2.7126e-04,  3.7763e-04,  1.4499e-04, -5.4798e-04,  5.8394e-04,\n              5.4264e-04, -3.1865e-04,  5.0749e-04,  1.2682e-04, -2.6704e-04,\n             -4.3085e-04, -5.3210e-05,  1.0184e-03,  7.6208e-04, -2.1689e-04,\n              1.0025e-04, -1.5537e-04,  3.1029e-04,  7.5911e-05,  3.3576e-04,\n              1.4041e-04, -5.3367e-04, -2.5824e-04, -3.6320e-04,  7.5077e-04,\n              4.9540e-04,  1.0368e-04,  8.1174e-05,  1.0861e-04,  5.3616e-04,\n              1.4403e-04,  2.7816e-02,  5.8150e-03,  3.8928e-02,  7.5929e-03,\n              9.6780e-03, -5.3912e-02, -1.9448e-02, -9.7823e-03, -7.3200e-03,\n              6.0155e-03, -1.6767e-02, -1.4041e-03,  2.1851e-02,  3.4146e-02,\n             -1.2456e-02, -2.8762e-02, -3.8001e-03,  1.4212e-02, -2.5653e-02,\n             -2.0294e-02,  1.5682e-03, -1.8228e-02, -1.0522e-02,  1.1869e-02,\n              2.6392e-03,  2.5630e-02, -7.3217e-03,  1.0832e-02, -1.1229e-02,\n             -8.8564e-04,  7.7057e-03,  1.8202e-02,  1.6470e-03,  5.5723e-03,\n             -1.4379e-02,  3.2612e-03, -1.1049e-02,  2.5871e-03,  1.7414e-02,\n             -6.8868e-03, -1.5628e-03,  1.8705e-02, -7.9803e-03, -5.7692e-03,\n              5.3905e-03, -1.1101e-02, -2.1128e-03, -1.0545e-02, -6.9868e-03,\n             -7.2935e-03,  1.1108e-02,  1.2436e-04, -1.5674e-02, -9.2862e-03,\n              6.6729e-03, -7.9500e-03,  3.0561e-03,  4.0034e-03,  9.3499e-03,\n              1.1548e-03,  3.5024e-03,  8.5390e-03, -1.4182e-02,  1.7703e-02,\n              4.8300e-03,  4.8930e-03, -8.5287e-03, -1.4533e-02,  3.4197e-03,\n              1.2757e-02, -2.1568e-02, -8.2429e-03, -6.3532e-03,  5.4615e-03,\n              1.4683e-02, -1.5968e-02,  8.2205e-03,  2.8455e-03, -1.5877e-02,\n             -3.8621e-04,  1.2156e-02,  4.0800e-03, -9.2215e-03,  1.1739e-02,\n              1.7043e-03, -4.4804e-03, -5.2887e-03,  4.6677e-03,  1.3812e-03,\n             -4.4391e-03,  1.5573e-02, -5.9835e-03, -6.4222e-03, -1.8496e-03,\n             -3.0196e-03, -1.1695e-02,  5.1999e-03,  2.6692e-03, -9.8021e-03,\n              7.5776e-03,  1.0398e-03, -1.1402e-02,  9.4614e-03,  1.3933e-02,\n              2.8825e-03,  7.6140e-03, -4.3531e-03,  9.1848e-03,  1.5852e-03,\n             -3.2356e-04, -5.7022e-03, -2.9227e-03,  1.8780e-03, -1.1010e-03,\n             -3.9234e-03, -1.8854e-03,  7.7043e-03, -7.2961e-03,  9.0933e-03,\n             -7.3330e-03, -2.9614e-03, -1.7347e-03,  1.5326e-02,  1.1287e-02,\n             -1.0173e-02,  3.7579e-04, -4.9439e-03, -1.4151e-02, -2.0601e-03,\n             -2.6843e-03,  2.7798e-03, -3.8943e-03,  1.0976e-02,  1.3910e-02,\n              6.7051e-03,  5.2856e-03,  7.9404e-03,  1.4797e-03,  1.3658e-03,\n             -5.7285e-03,  3.1045e-03,  3.0019e-03,  4.3561e-03, -6.4541e-03,\n             -5.1927e-03,  9.4693e-03,  1.0607e-02, -1.1268e-02,  5.2912e-03,\n              1.6782e-03, -1.4828e-02,  1.1670e-03, -1.0558e-04, -2.8111e-03,\n             -7.9571e-03,  5.7688e-04, -7.2648e-03, -3.9000e-03, -3.5122e-03,\n             -1.4120e-03,  2.1076e-03, -4.5840e-04,  9.8343e-03,  4.1263e-03,\n              1.6231e-03,  7.0824e-03,  2.4391e-03, -1.6820e-02,  8.2313e-03,\n             -3.5211e-03,  6.9049e-03,  3.8464e-03, -6.0936e-03,  1.2560e-02,\n              4.9004e-03, -1.1248e-03,  3.2139e-03, -2.6212e-03,  3.8854e-03,\n             -2.7544e-03, -9.6233e-04, -1.9959e-03, -9.2660e-04,  5.6140e-03,\n             -3.7575e-03, -1.1061e-02,  1.4546e-03,  2.4114e-03,  5.5914e-03,\n             -1.0051e-02,  4.3454e-03, -1.2115e-02,  2.9363e-03,  6.3246e-03,\n             -7.4251e-03,  6.3058e-04,  8.2153e-03,  1.5219e-03,  2.9236e-03,\n             -2.3916e-03,  3.2207e-03, -5.7162e-03, -1.4391e-03,  1.5226e-04,\n              3.5746e-03, -7.2148e-03, -9.7484e-03, -6.9893e-03,  1.5775e-03,\n             -4.8158e-03, -6.1756e-03, -6.6214e-04,  5.1643e-03,  6.8900e-03,\n              5.3396e-03, -2.2610e-03,  3.3412e-03,  5.1193e-03, -3.5101e-03,\n              4.0198e-03, -2.1122e-03,  1.5831e-03,  5.8820e-04,  1.5700e-03,\n              8.2490e-03,  6.7108e-03,  5.1533e-03,  8.9847e-03,  1.0243e-03,\n             -2.9712e-04,  5.3087e-03, -7.8802e-03,  5.0873e-03, -6.8960e-04,\n             -6.7587e-03,  2.5659e-03,  2.4101e-03,  2.7127e-03,  6.2432e-03,\n              7.0909e-03,  1.9857e-03,  3.2358e-03, -4.3509e-03,  3.7810e-04,\n             -8.3452e-03, -5.3246e-03, -3.7182e-04, -4.7713e-03,  2.9773e-03,\n             -1.5554e-03, -4.3483e-03, -9.0598e-03,  5.2326e-04, -7.1601e-03,\n             -3.2372e-03, -1.4320e-03]], device='cuda:0'),\n    'exp_avg_sq': tensor([[2.6688e-03, 8.1240e-04, 5.1415e-04, 4.2173e-04, 2.9185e-04, 2.9277e-04,\n             2.2900e-04, 2.0793e-04, 1.8481e-04, 1.7685e-04, 1.6104e-04, 1.4644e-04,\n             1.3825e-04, 1.3240e-04, 1.2136e-04, 9.5832e-05, 1.0479e-04, 9.9771e-05,\n             8.4118e-05, 8.1852e-05, 7.4984e-05, 7.4540e-05, 7.1469e-05, 6.5138e-05,\n             6.8899e-05, 6.1036e-05, 6.1652e-05, 5.5859e-05, 5.9994e-05, 5.0209e-05,\n             4.8662e-05, 5.0987e-05, 4.5791e-05, 4.6142e-05, 4.5304e-05, 4.6486e-05,\n             4.6864e-05, 4.2016e-05, 4.1533e-05, 3.8201e-05, 3.6598e-05, 3.7121e-05,\n             3.8500e-05, 3.3985e-05, 3.1686e-05, 3.2114e-05, 3.3188e-05, 3.0632e-05,\n             3.0186e-05, 3.2809e-05, 3.2454e-05, 3.0054e-05, 2.8562e-05, 2.9317e-05,\n             2.7478e-05, 2.6659e-05, 2.7905e-05, 2.6853e-05, 2.3995e-05, 2.3561e-05,\n             2.2853e-05, 2.3814e-05, 2.3133e-05, 2.3765e-05, 2.2674e-05, 2.2948e-05,\n             2.1651e-05, 2.1070e-05, 2.2292e-05, 2.0237e-05, 2.0089e-05, 1.9685e-05,\n             1.8801e-05, 1.9627e-05, 1.8758e-05, 1.9066e-05, 1.8149e-05, 1.8660e-05,\n             1.7295e-05, 1.7177e-05, 1.8146e-05, 1.6721e-05, 1.5971e-05, 1.4756e-05,\n             1.5318e-05, 1.4560e-05, 1.4715e-05, 1.4822e-05, 1.4681e-05, 1.4375e-05,\n             1.4825e-05, 1.4862e-05, 1.4443e-05, 1.3629e-05, 1.3524e-05, 1.3686e-05,\n             1.2363e-05, 1.2147e-05, 1.2696e-05, 1.2016e-05, 1.2252e-05, 1.2401e-05,\n             1.1611e-05, 1.1587e-05, 1.1973e-05, 1.1549e-05, 1.1485e-05, 1.0200e-05,\n             1.0930e-05, 1.0636e-05, 1.0355e-05, 1.1037e-05, 1.0953e-05, 1.0943e-05,\n             9.8841e-06, 9.3365e-06, 1.0280e-05, 1.0049e-05, 9.3436e-06, 9.4909e-06,\n             8.9751e-06, 9.2269e-06, 9.6471e-06, 8.6355e-06, 9.2656e-06, 8.5632e-06,\n             8.8441e-06, 8.2279e-06, 8.5408e-06, 8.4724e-06, 7.8789e-06, 8.1221e-06,\n             7.7752e-06, 7.9480e-06, 7.8215e-06, 8.0750e-06, 7.5449e-06, 7.6306e-06,\n             8.1379e-06, 7.0493e-06, 7.0089e-06, 7.1641e-06, 7.5895e-06, 7.4059e-06,\n             7.0030e-06, 7.3165e-06, 6.7175e-06, 6.5771e-06, 6.7130e-06, 6.5840e-06,\n             6.7121e-06, 6.3062e-06, 6.0075e-06, 6.2482e-06, 6.1235e-06, 6.0771e-06,\n             6.0127e-06, 6.2365e-06, 6.2477e-06, 6.1748e-06, 6.0286e-06, 6.0627e-06,\n             5.7561e-06, 5.7660e-06, 5.7315e-06, 5.3712e-06, 5.1175e-06, 5.3980e-06,\n             5.4971e-06, 5.4286e-06, 5.2246e-06, 5.2380e-06, 4.7229e-06, 4.9016e-06,\n             5.0814e-06, 4.7217e-06, 4.9863e-06, 5.0301e-06, 5.0519e-06, 4.7132e-06,\n             5.0171e-06, 4.4549e-06, 4.7573e-06, 4.6465e-06, 4.3194e-06, 4.5093e-06,\n             4.3031e-06, 4.3872e-06, 4.3961e-06, 3.9682e-06, 4.3694e-06, 4.0629e-06,\n             4.4820e-06, 4.1787e-06, 4.4218e-06, 4.0130e-06, 3.9752e-06, 3.8811e-06,\n             3.9519e-06, 3.9300e-06, 3.9384e-06, 3.6355e-06, 3.5489e-06, 3.8732e-06,\n             3.7763e-06, 3.7276e-06, 3.5707e-06, 3.5137e-06, 3.5337e-06, 3.6614e-06,\n             3.4149e-06, 3.3661e-06, 3.5539e-06, 3.2546e-06, 3.4923e-06, 3.1996e-06,\n             3.1764e-06, 3.2219e-06, 3.2694e-06, 3.4405e-06, 3.1267e-06, 3.1093e-06,\n             2.8565e-06, 3.1371e-06, 3.3198e-06, 2.9820e-06, 2.9804e-06, 2.8335e-06,\n             2.9796e-06, 2.7894e-06, 3.0829e-06, 3.0318e-06, 2.8870e-06, 2.8429e-06,\n             2.8415e-06, 2.7818e-06, 2.7807e-06, 2.7830e-06, 2.7066e-06, 2.5841e-06,\n             2.8099e-06, 2.5508e-06, 2.9241e-06, 2.4478e-06, 2.4528e-06, 2.4409e-06,\n             2.3425e-06, 2.2971e-06, 2.3909e-06, 2.4142e-06, 2.4985e-06, 2.3564e-06,\n             2.4527e-06, 2.4629e-06, 2.2951e-06, 2.2544e-06, 2.3978e-02, 1.5960e-02,\n             1.0384e-02, 1.0017e-02, 7.4698e-03, 7.3711e-03, 6.2220e-03, 6.5144e-03,\n             5.7966e-03, 4.9320e-03, 5.0988e-03, 4.2822e-03, 3.7788e-03, 3.9557e-03,\n             3.7156e-03, 3.7313e-03, 3.2987e-03, 3.1638e-03, 3.0832e-03, 3.2691e-03,\n             2.9982e-03, 2.7555e-03, 2.5636e-03, 2.4297e-03, 2.4590e-03, 2.3625e-03,\n             2.2134e-03, 2.2137e-03, 2.2221e-03, 2.0902e-03, 2.0217e-03, 2.0171e-03,\n             1.8799e-03, 1.8239e-03, 1.8875e-03, 1.8040e-03, 1.8537e-03, 1.5956e-03,\n             1.7025e-03, 1.6517e-03, 1.5441e-03, 1.5627e-03, 1.4817e-03, 1.4129e-03,\n             1.5411e-03, 1.4012e-03, 1.3998e-03, 1.2805e-03, 1.3355e-03, 1.3631e-03,\n             1.1975e-03, 1.2636e-03, 1.1939e-03, 1.2852e-03, 1.0893e-03, 1.1338e-03,\n             1.2421e-03, 1.1611e-03, 1.1665e-03, 1.1400e-03, 1.0122e-03, 1.0675e-03,\n             1.0797e-03, 1.0377e-03, 1.1206e-03, 1.0107e-03, 1.0396e-03, 1.0894e-03,\n             9.8436e-04, 1.0291e-03, 1.0154e-03, 1.0075e-03, 9.5089e-04, 1.0017e-03,\n             9.4153e-04, 8.6460e-04, 8.7388e-04, 8.3615e-04, 8.7131e-04, 8.8892e-04,\n             8.7590e-04, 8.1944e-04, 7.8394e-04, 8.6075e-04, 8.3285e-04, 7.9799e-04,\n             8.3015e-04, 7.9268e-04, 7.7521e-04, 7.1340e-04, 7.8340e-04, 7.5075e-04,\n             7.3012e-04, 7.7621e-04, 7.0120e-04, 7.0960e-04, 7.4086e-04, 7.3939e-04,\n             6.7532e-04, 7.2638e-04, 6.7530e-04, 7.5793e-04, 6.7283e-04, 6.9425e-04,\n             6.7626e-04, 6.7648e-04, 6.4816e-04, 6.4269e-04, 6.3667e-04, 6.6969e-04,\n             6.1428e-04, 6.0103e-04, 6.3122e-04, 5.8657e-04, 5.8273e-04, 5.7493e-04,\n             5.8165e-04, 5.8290e-04, 6.1109e-04, 5.8134e-04, 5.7028e-04, 5.6205e-04,\n             5.8991e-04, 5.8012e-04, 5.5195e-04, 5.4740e-04, 5.9355e-04, 5.7312e-04,\n             5.6416e-04, 5.5963e-04, 5.5307e-04, 5.7503e-04, 5.7474e-04, 5.1629e-04,\n             5.3489e-04, 5.4019e-04, 5.2833e-04, 5.1394e-04, 5.0333e-04, 5.3892e-04,\n             5.2191e-04, 5.2661e-04, 5.3129e-04, 4.9794e-04, 5.1073e-04, 4.9511e-04,\n             4.7331e-04, 5.1064e-04, 5.4035e-04, 4.9053e-04, 4.7065e-04, 4.7652e-04,\n             4.9281e-04, 4.8169e-04, 4.6795e-04, 4.6427e-04, 4.6916e-04, 4.3844e-04,\n             4.6940e-04, 4.5366e-04, 4.6980e-04, 4.5950e-04, 4.3696e-04, 4.7143e-04,\n             4.3784e-04, 4.1878e-04, 4.3478e-04, 4.4567e-04, 4.3704e-04, 4.3030e-04,\n             4.6163e-04, 4.3046e-04, 4.1415e-04, 4.0656e-04, 3.7757e-04, 4.2819e-04,\n             4.2404e-04, 3.9312e-04, 3.9750e-04, 3.9723e-04, 3.9739e-04, 4.0460e-04,\n             4.1015e-04, 3.8335e-04, 3.7787e-04, 4.1084e-04, 3.9174e-04, 3.7647e-04,\n             3.9354e-04, 3.8342e-04, 3.9638e-04, 3.9076e-04, 3.6604e-04, 3.6480e-04,\n             3.6719e-04, 3.6912e-04, 4.0921e-04, 3.5966e-04, 3.4151e-04, 3.5110e-04,\n             3.6337e-04, 3.6315e-04, 3.4415e-04, 3.5023e-04, 3.4997e-04, 3.5025e-04,\n             3.7639e-04, 3.8098e-04, 3.4265e-04, 3.4680e-04, 3.5324e-04, 3.3389e-04,\n             3.4569e-04, 3.2919e-04, 3.3350e-04, 3.3749e-04, 3.3041e-04, 3.3454e-04,\n             3.2386e-04, 3.3411e-04, 3.1752e-04, 3.5453e-04, 3.2395e-04, 2.9758e-04,\n             3.1792e-04, 2.9256e-04, 2.9935e-04, 3.1007e-04, 3.1221e-04, 3.1614e-04,\n             2.8577e-04, 2.9764e-04, 2.9946e-04, 2.9541e-04, 2.9998e-04, 2.8350e-04,\n             2.6974e-04, 2.8758e-04, 2.6984e-04, 2.9115e-04, 3.0173e-04, 2.8709e-04,\n             2.9469e-04, 2.6684e-04, 2.7832e-04, 2.6785e-04, 2.6214e-04, 2.8327e-04,\n             2.6018e-04, 2.5913e-04, 2.7694e-04, 2.6649e-04, 2.8122e-04, 2.7372e-04,\n             2.7436e-04, 2.6311e-04]], device='cuda:0')},\n   3: {'step': tensor(1750.),\n    'exp_avg': tensor([-0.0854], device='cuda:0'),\n    'exp_avg_sq': tensor([0.0076], device='cuda:0')},\n   4: {'step': tensor(1750.),\n    'exp_avg': tensor([[-1.8273e-02, -9.1086e-03,  1.7667e-03,  9.8509e-03, -1.5238e-03,\n              1.5885e-03,  3.4106e-03, -9.0078e-03, -6.8779e-04,  1.5514e-03,\n             -6.7232e-03, -3.9056e-04, -1.5724e-03, -2.2030e-03,  2.2556e-03,\n              4.2591e-03, -3.4466e-03, -3.4123e-03, -4.3374e-03, -2.3936e-03,\n             -6.0905e-04,  2.0862e-04, -1.3524e-03,  7.6352e-04, -1.1296e-03,\n              1.7055e-03, -5.7141e-04,  3.2190e-03, -4.1959e-03,  2.8244e-03,\n             -9.4198e-04, -1.1211e-03, -8.3486e-04, -4.4855e-05,  8.9901e-04,\n             -2.1449e-04, -4.1680e-04, -8.4565e-04, -6.4597e-04,  9.6486e-04,\n              2.1545e-03, -1.2316e-03,  1.9158e-03, -1.1364e-03,  7.8074e-04,\n             -1.0812e-03,  2.5081e-04,  1.5274e-03, -5.1071e-04,  1.5148e-03,\n              1.5115e-03,  1.0494e-03, -1.4666e-03,  6.3948e-04,  1.2345e-03,\n              1.1628e-03,  1.4934e-03,  4.1789e-03, -2.8555e-04, -5.3543e-04,\n              1.5881e-04, -3.0929e-03, -1.3683e-04,  1.5798e-03, -1.8964e-03,\n              1.8923e-03,  3.4857e-04, -2.0047e-04,  2.1754e-04, -1.9989e-03,\n              1.5489e-03, -1.2625e-03, -4.0278e-04, -4.7318e-04, -8.0435e-04,\n              7.7657e-04,  4.8295e-04,  7.8232e-04, -1.1239e-04, -3.9972e-04,\n              7.2627e-04,  2.6985e-04, -6.6487e-04, -3.0870e-04, -5.3949e-04,\n             -6.4673e-04, -2.1511e-04, -1.1127e-03,  1.0398e-03,  4.2943e-04,\n             -5.1989e-04, -7.2052e-04, -5.4462e-04,  7.4379e-04,  1.0637e-03,\n             -4.6478e-04,  1.0259e-03, -2.2067e-03,  5.4212e-04, -1.1568e-03,\n             -3.4464e-04, -8.8720e-04,  2.2980e-03,  9.9457e-04, -3.0404e-04,\n              1.1949e-03,  7.9010e-04, -5.3125e-04,  2.7503e-04, -4.0104e-04,\n              4.9002e-04,  3.6806e-04,  4.5638e-04, -5.2952e-05, -5.9784e-05,\n             -1.0377e-03, -4.9170e-04, -3.4700e-04,  6.8857e-05, -5.6476e-05,\n              2.8135e-04,  1.1261e-03, -1.6386e-03,  2.6548e-04, -7.5379e-04,\n              6.3611e-04, -1.1659e-03, -6.3247e-05,  3.4549e-04,  2.1691e-03,\n              1.5955e-03, -5.5417e-04, -8.0101e-04,  2.1411e-04, -4.5294e-04,\n              5.8488e-04,  9.6541e-04,  2.1294e-03,  1.6916e-04,  3.7481e-04,\n              2.2328e-04,  1.2059e-03, -5.7283e-04,  7.2760e-05,  9.7369e-04,\n             -1.9521e-04, -6.1679e-04,  1.5289e-04,  2.0559e-04,  7.4569e-04,\n              9.6754e-04, -5.5676e-04,  3.8412e-04,  1.3914e-04, -7.4758e-04,\n             -2.1240e-04, -3.4954e-04, -8.1545e-04, -5.5529e-04, -2.3453e-04,\n              7.5881e-04,  8.4655e-05,  2.4573e-04, -4.0786e-04, -8.3858e-04,\n              1.0783e-04, -8.7474e-04,  2.0634e-04,  1.2825e-04, -6.3403e-04,\n              4.1610e-05, -7.2410e-04,  3.5590e-04,  2.0074e-04,  1.4473e-04,\n              2.6601e-04,  8.9547e-05,  9.1612e-04,  1.0050e-04,  5.1024e-04,\n             -1.3216e-04, -6.3337e-04, -2.6400e-04,  2.0105e-04, -2.9260e-04,\n              5.5890e-04,  7.5471e-04,  8.3045e-05, -1.5193e-04,  4.5705e-04,\n              4.6351e-04, -2.9502e-04, -8.5436e-04, -7.6341e-04,  1.0934e-03,\n             -8.7186e-04,  4.5486e-05,  5.7141e-05, -7.6879e-04,  7.9257e-04,\n              1.1391e-03,  6.3988e-04, -1.0379e-04,  2.0095e-05,  4.2216e-04,\n             -3.8131e-04, -8.1032e-04,  1.2095e-03, -2.3399e-04,  5.8285e-04,\n             -1.2851e-03, -4.7689e-04, -3.9787e-04, -8.9914e-04, -8.6281e-05,\n             -3.0363e-04, -6.6292e-04, -4.0313e-04, -9.3100e-04,  8.0957e-05,\n             -1.1794e-04, -4.8226e-04,  4.2111e-04,  3.5039e-05,  3.7444e-04,\n             -1.9691e-04,  3.6756e-04, -5.4394e-04,  1.0605e-04, -9.6718e-05,\n             -1.4550e-04,  1.8025e-04,  9.1471e-05, -5.1584e-04,  6.0271e-06,\n             -3.1935e-04, -4.6493e-04,  7.3262e-04,  7.5171e-04,  9.3349e-06,\n             -7.3898e-05, -4.5036e-04,  5.0299e-04,  2.5645e-04,  1.7339e-04,\n              4.5990e-04, -5.4579e-05, -1.3468e-04, -1.0406e-03,  5.6263e-05,\n             -5.8539e-05,  3.6645e-04,  1.8051e-04,  1.4104e-04,  7.8990e-05,\n             -2.2929e-04, -4.9465e-03,  5.3031e-02,  3.4802e-02,  4.4586e-02,\n             -1.3966e-02,  1.0314e-02, -2.0756e-02,  1.2284e-02, -2.3324e-02,\n              8.8521e-04,  1.2045e-02, -5.5814e-03,  1.1150e-02,  1.6952e-02,\n             -2.3340e-02, -8.8530e-03, -1.0132e-02, -5.0331e-03, -2.7963e-03,\n              9.8433e-03,  3.3637e-02, -6.5745e-03,  4.2953e-03, -2.5862e-03,\n             -3.6754e-03,  4.0706e-02, -1.1297e-02, -1.6939e-03, -8.5652e-03,\n              1.8047e-02, -2.2703e-03,  4.2949e-03, -3.6038e-04,  4.9366e-03,\n             -1.9248e-02,  5.5833e-03,  6.6295e-03, -4.1371e-03, -7.1540e-03,\n              1.0271e-02,  4.3515e-03, -1.2358e-02, -3.8644e-03,  4.5882e-03,\n              6.2408e-04, -9.0077e-03,  3.6353e-03, -5.7711e-03, -5.9285e-03,\n              3.7663e-03, -3.9262e-03, -1.0859e-02, -4.7255e-03,  3.9904e-04,\n              9.4658e-03,  1.4086e-02, -1.3427e-03,  7.1088e-03,  5.6176e-04,\n              1.9739e-02,  1.4104e-02, -8.5963e-03,  1.7331e-03,  5.8806e-03,\n             -4.0011e-03, -2.3245e-03, -9.5114e-03, -1.2584e-03,  3.2307e-03,\n              3.7055e-03, -3.6113e-03,  1.3640e-02,  4.4641e-04,  2.2028e-04,\n              1.3724e-03, -4.8341e-03,  1.0433e-02, -6.6409e-03, -1.8682e-04,\n             -5.0149e-03,  1.1294e-02,  1.0698e-03, -2.7316e-03, -3.1514e-04,\n              4.5750e-03, -1.9692e-03, -3.2505e-03, -3.5127e-03, -3.3527e-03,\n              6.0162e-03,  1.7402e-02,  1.5266e-04,  3.3661e-03,  3.0746e-03,\n              6.9697e-03,  5.1635e-03,  7.2353e-03,  3.8600e-03,  5.0535e-03,\n              1.2733e-03, -6.1770e-03,  6.5978e-04, -1.0975e-03,  4.3495e-03,\n             -5.7848e-03, -7.5650e-03,  5.6105e-03,  5.5068e-03,  4.3466e-05,\n              1.0615e-02,  4.5883e-03,  1.1897e-02, -9.3969e-04, -5.2027e-03,\n             -8.5535e-03,  5.8485e-03,  1.5090e-02, -1.2868e-02,  4.1280e-03,\n             -2.3533e-03, -2.5626e-03, -4.8685e-03,  6.6191e-03,  4.8724e-03,\n             -6.4854e-03,  2.8590e-03, -6.2688e-03, -1.8960e-03, -5.3149e-03,\n              3.8763e-03, -4.9543e-03,  2.7296e-03,  4.8272e-05,  1.2566e-02,\n             -1.2636e-03, -1.4023e-03,  3.9233e-03, -6.5397e-03, -6.6383e-03,\n             -2.9779e-03, -1.3688e-04, -5.1636e-03,  8.0864e-03,  2.8047e-04,\n             -9.8342e-03,  9.4010e-03,  4.8608e-03, -1.6937e-03, -1.0820e-02,\n              2.3335e-03, -1.1546e-02,  5.5175e-03,  2.4981e-04, -5.2333e-03,\n              1.2548e-03, -5.4949e-03, -4.0966e-03, -4.2793e-03,  1.6687e-03,\n              1.0203e-03,  3.5504e-03, -6.6682e-03, -4.6831e-04, -6.7947e-03,\n             -9.8965e-03,  8.5638e-04,  2.6957e-03, -4.5758e-03, -9.7223e-04,\n              1.6853e-04, -3.5052e-03, -1.7720e-03,  3.0574e-03,  7.3898e-03,\n              1.3475e-02,  3.5187e-03,  1.4339e-03,  3.6432e-03,  2.8199e-03,\n              4.7573e-03,  6.5415e-03,  2.0922e-03, -4.9828e-03,  2.5024e-04,\n              2.1173e-03,  1.9789e-03, -2.0427e-03, -4.2699e-03, -1.2933e-03,\n             -1.0238e-02,  2.0623e-03,  6.6695e-04, -1.0650e-02,  6.8997e-03,\n             -8.4979e-03,  6.9231e-03,  2.0873e-03,  6.1121e-03, -4.3166e-03,\n              2.3753e-03,  4.2068e-03,  2.1607e-03, -3.2224e-03,  6.1202e-05,\n              4.1689e-03, -3.1732e-04, -4.7041e-03, -2.5197e-03,  6.1103e-03,\n              3.5907e-03, -2.6228e-03,  6.2033e-03, -2.3369e-03,  5.9930e-03,\n             -2.0728e-04, -2.5717e-03,  4.7341e-04,  7.0579e-04, -3.4063e-03,\n             -2.4318e-03,  6.8653e-03, -6.1142e-03,  3.0388e-03, -2.1549e-03,\n             -3.1650e-03, -2.5308e-03,  2.6813e-03,  1.0296e-02, -1.4801e-03,\n              6.2594e-03,  2.1671e-03, -5.4904e-03,  6.6893e-03, -2.7695e-03,\n             -6.5671e-03, -4.3869e-04,  6.9063e-03,  4.4752e-03,  6.4501e-03,\n              3.0068e-03, -2.8763e-03,  1.5949e-03,  2.5138e-03, -4.4961e-03,\n             -4.8173e-03, -4.9850e-03, -1.2832e-02, -2.2632e-03,  5.6557e-03,\n             -1.4487e-03, -2.2321e-03, -9.5909e-05, -9.3132e-03, -3.6537e-03,\n             -1.2814e-03, -7.1956e-04]], device='cuda:0'),\n    'exp_avg_sq': tensor([[2.4443e-03, 8.5773e-04, 5.2821e-04, 4.5116e-04, 2.9257e-04, 2.8717e-04,\n             2.2155e-04, 2.2313e-04, 2.0059e-04, 1.6708e-04, 1.5983e-04, 1.4135e-04,\n             1.3653e-04, 1.2472e-04, 1.2044e-04, 9.8379e-05, 1.0331e-04, 9.1810e-05,\n             8.7115e-05, 8.3495e-05, 7.5525e-05, 7.2644e-05, 7.1565e-05, 6.8479e-05,\n             6.2843e-05, 6.3791e-05, 5.9141e-05, 5.8344e-05, 5.0670e-05, 5.4700e-05,\n             5.1694e-05, 5.1036e-05, 4.8603e-05, 4.7836e-05, 4.4624e-05, 4.2798e-05,\n             4.4241e-05, 4.4209e-05, 3.9959e-05, 3.8782e-05, 3.5635e-05, 3.6747e-05,\n             3.2529e-05, 3.6816e-05, 3.5776e-05, 3.1753e-05, 3.4638e-05, 3.2544e-05,\n             3.2657e-05, 3.2097e-05, 2.9152e-05, 3.0564e-05, 2.7330e-05, 2.9776e-05,\n             2.8441e-05, 2.6375e-05, 2.5820e-05, 2.6975e-05, 2.3430e-05, 2.4500e-05,\n             2.4120e-05, 2.4726e-05, 2.3019e-05, 2.3750e-05, 2.2923e-05, 2.2432e-05,\n             2.3309e-05, 2.1722e-05, 2.0868e-05, 2.0269e-05, 1.9612e-05, 1.9335e-05,\n             1.9087e-05, 1.7820e-05, 1.8832e-05, 1.8623e-05, 1.9341e-05, 1.8695e-05,\n             1.7659e-05, 1.6328e-05, 1.7145e-05, 1.6925e-05, 1.6532e-05, 1.5461e-05,\n             1.5830e-05, 1.5572e-05, 1.5705e-05, 1.5342e-05, 1.4756e-05, 1.5650e-05,\n             1.4276e-05, 1.4880e-05, 1.5607e-05, 1.3800e-05, 1.2946e-05, 1.2860e-05,\n             1.2788e-05, 1.2699e-05, 1.2064e-05, 1.3294e-05, 1.1960e-05, 1.2907e-05,\n             1.2710e-05, 1.2552e-05, 1.2138e-05, 1.2068e-05, 1.1906e-05, 1.0705e-05,\n             1.1624e-05, 1.1678e-05, 1.0858e-05, 1.1283e-05, 1.0976e-05, 1.0297e-05,\n             1.0636e-05, 9.4346e-06, 1.0045e-05, 9.8361e-06, 9.4500e-06, 9.1816e-06,\n             1.0050e-05, 9.1313e-06, 8.4532e-06, 8.5585e-06, 9.7189e-06, 8.7807e-06,\n             8.7237e-06, 8.3598e-06, 8.7219e-06, 8.8588e-06, 8.3960e-06, 8.1478e-06,\n             7.9418e-06, 7.9036e-06, 8.7485e-06, 7.6391e-06, 7.8828e-06, 7.9463e-06,\n             7.6922e-06, 7.1401e-06, 7.1171e-06, 7.4630e-06, 7.3274e-06, 7.1976e-06,\n             7.1117e-06, 7.4757e-06, 6.7097e-06, 7.1211e-06, 7.2688e-06, 6.9268e-06,\n             6.4539e-06, 6.6779e-06, 6.5060e-06, 6.4074e-06, 6.6353e-06, 6.5164e-06,\n             6.3851e-06, 6.0594e-06, 5.9874e-06, 6.3357e-06, 6.3838e-06, 5.7871e-06,\n             5.5854e-06, 5.5553e-06, 5.5511e-06, 5.7232e-06, 5.2481e-06, 5.2053e-06,\n             5.7368e-06, 5.6722e-06, 5.5456e-06, 5.3062e-06, 4.8635e-06, 4.8769e-06,\n             4.8787e-06, 4.4327e-06, 4.8464e-06, 5.1823e-06, 5.0249e-06, 4.6681e-06,\n             5.0058e-06, 4.4092e-06, 4.6862e-06, 4.3313e-06, 4.7581e-06, 4.4598e-06,\n             4.3645e-06, 4.3112e-06, 4.4521e-06, 4.3837e-06, 4.5545e-06, 4.1009e-06,\n             4.4630e-06, 4.1012e-06, 4.2871e-06, 4.0934e-06, 3.9506e-06, 3.6650e-06,\n             3.9301e-06, 3.9701e-06, 3.9520e-06, 3.8351e-06, 3.4368e-06, 3.6696e-06,\n             3.7606e-06, 3.4967e-06, 3.6884e-06, 3.9122e-06, 3.5467e-06, 3.5292e-06,\n             3.6253e-06, 3.3225e-06, 3.5324e-06, 3.3021e-06, 3.4977e-06, 3.4680e-06,\n             3.2643e-06, 3.1891e-06, 3.3684e-06, 3.1178e-06, 3.4043e-06, 3.1891e-06,\n             3.1198e-06, 3.0965e-06, 3.1082e-06, 3.1436e-06, 2.8065e-06, 3.0254e-06,\n             3.0151e-06, 2.9334e-06, 2.9831e-06, 2.8705e-06, 2.8228e-06, 2.8120e-06,\n             2.5045e-06, 2.6328e-06, 2.6038e-06, 2.7173e-06, 2.7162e-06, 2.7547e-06,\n             2.6029e-06, 2.7481e-06, 2.6621e-06, 2.4871e-06, 2.5334e-06, 2.5083e-06,\n             2.4807e-06, 2.3252e-06, 2.3397e-06, 2.3110e-06, 2.4880e-06, 2.3364e-06,\n             2.3018e-06, 2.3854e-06, 2.2871e-06, 2.2424e-06, 1.9078e-02, 1.5423e-02,\n             1.1399e-02, 9.2740e-03, 7.4622e-03, 6.7004e-03, 6.6506e-03, 5.8838e-03,\n             5.5519e-03, 5.1940e-03, 4.3940e-03, 4.1417e-03, 3.7573e-03, 3.5748e-03,\n             3.4795e-03, 3.5359e-03, 3.5928e-03, 3.0083e-03, 3.0730e-03, 3.0277e-03,\n             2.7088e-03, 2.6398e-03, 2.6847e-03, 2.5319e-03, 2.4382e-03, 2.4352e-03,\n             2.2016e-03, 2.2121e-03, 2.0273e-03, 2.2269e-03, 2.1451e-03, 1.8432e-03,\n             1.9475e-03, 1.8357e-03, 1.8143e-03, 1.7627e-03, 1.8036e-03, 1.8084e-03,\n             1.5674e-03, 1.5460e-03, 1.4696e-03, 1.5890e-03, 1.5173e-03, 1.4537e-03,\n             1.4302e-03, 1.4911e-03, 1.4364e-03, 1.4239e-03, 1.3791e-03, 1.3242e-03,\n             1.2888e-03, 1.2416e-03, 1.1603e-03, 1.2386e-03, 1.1789e-03, 1.1794e-03,\n             1.1057e-03, 1.1137e-03, 1.1380e-03, 1.1972e-03, 1.1328e-03, 1.1054e-03,\n             1.0683e-03, 9.9489e-04, 1.0636e-03, 1.0034e-03, 1.0084e-03, 9.9582e-04,\n             9.6553e-04, 9.7657e-04, 9.0852e-04, 9.5559e-04, 9.3530e-04, 9.4480e-04,\n             9.2642e-04, 8.5864e-04, 8.7259e-04, 8.5958e-04, 8.7757e-04, 8.9675e-04,\n             8.1954e-04, 8.2594e-04, 8.6320e-04, 7.9333e-04, 8.5784e-04, 7.9685e-04,\n             8.1380e-04, 8.0977e-04, 7.9296e-04, 7.2108e-04, 7.5404e-04, 7.3360e-04,\n             7.1487e-04, 7.1087e-04, 7.1726e-04, 7.1296e-04, 7.3510e-04, 6.7685e-04,\n             6.8982e-04, 6.9737e-04, 7.4691e-04, 6.7180e-04, 6.8934e-04, 6.9351e-04,\n             6.7316e-04, 6.7929e-04, 6.6296e-04, 6.3439e-04, 6.1554e-04, 6.5021e-04,\n             6.2601e-04, 6.2300e-04, 6.3103e-04, 6.2897e-04, 6.1468e-04, 5.9017e-04,\n             6.0373e-04, 6.2287e-04, 6.1561e-04, 5.8483e-04, 6.0454e-04, 6.0217e-04,\n             5.9719e-04, 5.9762e-04, 5.6815e-04, 5.6491e-04, 6.1311e-04, 5.2105e-04,\n             5.8071e-04, 5.3123e-04, 5.5108e-04, 5.5176e-04, 5.5186e-04, 5.3704e-04,\n             5.0959e-04, 5.6415e-04, 5.5469e-04, 5.0301e-04, 5.3367e-04, 4.9150e-04,\n             4.6266e-04, 5.3290e-04, 5.1208e-04, 5.3560e-04, 5.1821e-04, 5.0726e-04,\n             5.1575e-04, 5.2722e-04, 4.9610e-04, 5.2116e-04, 4.9587e-04, 5.0129e-04,\n             4.5594e-04, 4.6614e-04, 4.6295e-04, 4.6971e-04, 4.7272e-04, 4.5114e-04,\n             4.9107e-04, 4.7289e-04, 4.3564e-04, 4.2305e-04, 4.4621e-04, 4.2818e-04,\n             4.4677e-04, 4.5462e-04, 4.8221e-04, 4.3203e-04, 4.2695e-04, 4.2202e-04,\n             3.9824e-04, 4.2123e-04, 4.2067e-04, 3.9656e-04, 4.2138e-04, 4.3008e-04,\n             4.1642e-04, 3.9987e-04, 3.7736e-04, 4.0060e-04, 4.0169e-04, 4.0124e-04,\n             3.8365e-04, 4.0994e-04, 3.8819e-04, 3.9437e-04, 3.7858e-04, 3.8382e-04,\n             3.9940e-04, 3.9519e-04, 4.0742e-04, 3.8622e-04, 3.6755e-04, 3.9686e-04,\n             3.8550e-04, 3.8053e-04, 3.6558e-04, 3.7618e-04, 3.6666e-04, 3.6205e-04,\n             3.6343e-04, 3.6774e-04, 3.3822e-04, 3.7273e-04, 3.3473e-04, 3.4815e-04,\n             3.5534e-04, 3.3838e-04, 3.4819e-04, 3.4307e-04, 3.4850e-04, 3.4684e-04,\n             3.2122e-04, 3.2851e-04, 3.2707e-04, 3.5258e-04, 3.6470e-04, 3.4267e-04,\n             3.2639e-04, 3.2507e-04, 3.2360e-04, 3.1551e-04, 3.0928e-04, 3.2626e-04,\n             3.2564e-04, 3.1951e-04, 2.9402e-04, 3.2247e-04, 2.8345e-04, 3.2221e-04,\n             3.2952e-04, 3.0310e-04, 3.0379e-04, 2.9706e-04, 2.9047e-04, 3.0405e-04,\n             2.8096e-04, 2.8915e-04, 2.7319e-04, 2.9252e-04, 2.9961e-04, 2.7939e-04,\n             2.7634e-04, 2.6762e-04, 2.5586e-04, 2.6854e-04, 2.8012e-04, 2.8369e-04,\n             2.8397e-04, 2.7579e-04, 2.5881e-04, 2.6796e-04, 2.6246e-04, 2.6587e-04,\n             2.7176e-04, 2.5671e-04]], device='cuda:0')},\n   5: {'step': tensor(1750.),\n    'exp_avg': tensor([-0.0365], device='cuda:0'),\n    'exp_avg_sq': tensor([0.0020], device='cuda:0')}},\n  'param_groups': [{'lr': 2e-05,\n    'betas': (0.9, 0.999),\n    'eps': 1e-08,\n    'weight_decay': 0.01,\n    'amsgrad': False,\n    'foreach': None,\n    'maximize': False,\n    'capturable': False,\n    'differentiable': False,\n    'fused': None,\n    'params': [0, 1, 2, 3, 4, 5]}]},\n 'loss': tensor(0.6540, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>),\n 'val_f1': 0.44646859714816084}"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}